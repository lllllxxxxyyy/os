# 3.1 简单程序的结构

## 一.运行时视图

### 1.1代码段

**运行时视图** 程序在执行时的主存储器布局。也叫运行时布局。

![image-20230321190706992](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321190706992.png)

**代码段（.text）** 存放程序的可执行指令，所有的执行都在代码段发生。

### 1.2数据段

**数据段（.data）**存放程序的数据，又可以细分成三类。

- **只读数据段（.rodata）**

存放程序中的含初值常量。这些常量在程序运行途中**不得修改**

- **读写数据段（.rwdata）**

存放程序中的含初值常量。这些常量在程序运行**可以修改**。

- **零初始化数据段（.zidata/.bss - Block Started by Symbol）**

存放程序中的不含初值（初始化为0的）可修改常量

### 1.3堆段与栈段

- **堆段（.heap）**

存放程序的堆，也即动态分配内存时内存的来源。

- **栈段（.stack）**


存放程序的运行栈，以供过程调用时保存和恢复上下文。

## 二.程序的装入

### 2.1代码的搬运

**上电状态** 与外存不同，内存在刚通电时内容是空的。

**问题** 至少哪些段需要放在内存里面？提示：要求可读写属性。

### ![image-20230321191759687](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321191759687.png)

**问题** 那么，只读段呢？能从外存直接运行代码吗？

 一般不行，除非外存是特制的，允许按字读取，也即可原位执行（XIP，eXecute-In-Place）。这在小型嵌入式设备中（Flash） 很常见。在这种场合，我们可以假设代码段已经到位了，由代 码段去加载其它段。但如果代码段也没加载呢？

**程序的装入** 这意味着内存中现在没有任何与这个程序相关的东西。因此， 需要操作系统从外存读取程序文件的逻辑段，并按照其属性装入内存中。

**外存上的程序** 程序在外存上又是如何保存的呢？哪些段是必须保存的？除了 保存这些段的内容，还必须保存这些段的什么信息？



**可执行文件** 程序在外存上的储存方式，本质是保存了程序的逻辑布局的描述。

**程序的装入** 操作系统读取外存上的可执行文件中对程序逻辑布局的描述 （Description），在内存中生成程序的物理布局的一个实例 （Instance）的过程。

**可执行文件头** 描述程序运行时布局的元数据，一般附加在可执行文件头部。

![image-20230321192345548](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321192345548.png)

### 2.2数据的搬运

![image-20230321193124624](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321193124624.png)

**代码段**

操作系统从可执行文件中读取代码段，并拷贝到内存中的指定地址。

操作系统在拷贝完成后设定该段为可读可执行段。

**只读数据段**

与代码段类似的拷贝过程。

**可读写数据段**

操作系统**从可执行文件中**读取可读写数据段，并拷贝到内存中的指定地址

**零初始化数据段**

操作系统将**内存**中的指定地址清零。

**堆段**

操作系统在**内存**中的指定地址初始化堆数据结构。

**栈段**

操作系统通常对该段什么也不做。

最后，在将控制权交给程序时，将**PC指向.text段，将SP指向.stack段**



## 三.程序的生成

### 3.1编程语言与工具链

**编译器、汇编器、链接器、调试器与解释器程序**

**编译器** 把**高级语言**源程序翻译成**机器语言**程序。

 有时也先翻译成汇编语言源程序，然后调用汇编器。

 如：GCC（C，C++等）、MSVC（C，C++等）。

**汇编器** 把**汇编语言**源程序翻译成**机器语言**程序。

 如：AS，MASM，TASM。

**链接器** 将**机器语言程序中间文件**与**系统运行库**链接生成**可执行的机器语言**程序。可能重定位各个段的位置。

 如：LD，LINK。

**调试器** 系统提供给用户的能监督和控制用户程序的一种工具，可以装入、 修改、显示或逐条执行一个程序。

 如：GDB，DEBUG。

**解释器** **直接在机器上解释并执行高级语言源程序**。

 **也不排斥使用编译器技术**，内部先生成机器语言程序再执行。但是，解释器一般**不会生成可独立运行的机器语言程序文件**。

 如：Lua、JavaScript、Python。



**工具链**

 编写、链接、调试应用程序往往需要一系列工具的帮助，这一 系列工具被称为工具链。

**工具链**  基本的编译工具链必须包括编译器、汇编器和链接器，否则无 法生成应用程序。若条件允许，还要包含调试器以便增进调试效率。

![image-20230321193821814](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321193821814.png)

**编译器**

**编译器** 负责将输入的**高级**语言源程序翻译为**汇编**语言源程序。

**高级源程序** 程序员**手工编写的高级语言程序**。一个高级语言程序可以由多 个编译单元**（*.C/*.CPP）**组成，需要针对每个编译单元调用一次 编译器，分别生成对应于它们的汇编文件**（*.S/*.ASM）**。

 当然，现代编译器都具备**直接生成机器码目标文件（*.O/*.OBJ）** 等的能力，可以跳过汇编文件这一步，只是原则上经过了汇编 语言这一层次。

**清单列表文件** :**供程序员参考的一些可选信息**，诸如生成的汇编程序具体与高级语言怎样对应等等，甚至生成混合高级语言代码与汇编代码 的参考文件。这些信息对工具链是无用的，对程序员则很有用



**汇编器**

**汇编器** 负责将输入**源程序**中的指令进行**组装**，生成初步的机器码**目标文件**。有时，汇编器还生成供程序员参考的**清单列表文件**。

**汇编源程序** 程序员**手工编写的汇编语言程序**。一个汇编语言程序可以由多 个汇编单元**（*.ASM）**组成，需要针对每个汇编单元调用一次汇 编器，分别生成其目标文件。

**目标文件** 汇编器组装指令得到的、包含初步机器码的文件**（*.OBJ)**。这些 文件还不能直接被执行，需要进一步链接，确定程序中所含地 址的确切值后才可以直接被执行。

**清单列表文件** 供**程序员**参考的一些**可选信息**，诸如生成的机器码具体与汇编程序怎样对应、某些定义在第几行被定义，在第几行被引用等等。这些信息**对链接器无用**，完全是为程序员方便而引入的。

 在MASM中，*.LST文件负责前者，*.CRF文件负责后者，但是只 有*.LST文件是文本文件，*.CRF则是需经转换才可读的文件。



**链接器**

**链接器** 负责确定程序各部分所对应的**具体地址**，并根据该地址**填充所有符号引用、生成最终可执行二进制文件**。有时，链接器还生 成供程序员参考的地址映射文件。

**可执行文件** 可直接在操作系统中执行的应用程序**（*.EXE或*.COM）**，含有完全成熟的、可直接执行的机器码。

**地址映射文件** 供**程序员**参考的一些**可选地址映射信息**，诸如某段程序或数据最终被链接到哪个地址，等等。

![image-20230321201309943](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321201309943.png)





### 3.2程序的编译与链接

**目标文件的内容**

**外部符号引用** 在一个目标文件中可能**引用了其它目标文件的内容**。由于编译器一次生成一个目标文件，因此并不知道那些引用的内容的地址在哪。况且，**自身在内存中的位置也还没确定**，因此所有对符号的引用（全局变量访问、函数调用等等）的具体地址都**只能推迟**。

**extern关键字** 表明引用的符号在当前的C或C++编译单元中未被定义，需要到**其它编译单元**中去寻找。在调用外部过程库时相当常用。

**链接器的操作** 链接器会先**收集全部目标文件的符号**，然后给每个符号**分配地址**。在地址确定后，**反过来补全**程序中对这些符号地址的引用。

**直接回填法**

**直接回填** 链接器生成所有符号的地址后，直接修改.text段中对这些符号的引用，将正确的地址填写到那些引用中去，这样生成的代码就 可以访问那些符号了。

 直接回填法会**修改.text段。**

**间接地址法**

**间接地址** 编译器或汇编器生成目标文件时，在.rwdata段留出一个表格，.text段中的代码对其它符号的引用均通过这个表格进行。

 间接地址法不会修改.text段，但会**修改.rwdata段**。

### 3.3过程调用与栈框

**过程（子程序）结构**

程序指针可能在中途反复跳转到同一段过程执行，完毕后返回原处继续执行。

比循环结构更强大，因为过程的尾递归可以实现循环。过程还可以嵌套。

![image-20230321203024098](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321203024098.png)



**简单过程程序**

**近过程型**调用者和被调用者处于同一代码段中，NEAR和PTR可以不写

**远过程型**调用者和被调用者处于不同的代码段内，FAR至少写一处

**复杂过程程序**

**含参数型**调用者向被调用者传递一个或多个参数，参数传递有三种方法

（1)通过**全局变量**传递（需要在数据段声明）

（2）通过**栈**传递（记得设置SP和SS）

（3）通过**寄存器**传递（寄存器数量有限）

**返回值型**被调用者向调用者返回一个或多个返回值

返回值的传递和参数一样，也有三种方法：（1)通过**全局变量**传递（需要在数据段声明）

（2）通过**栈**传递（记得设置SP和SS）

（3）通过**寄存器**传递（寄存器数量有限）

**栈的四种类型**

![image-20230323105502287](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230323105502287.png)

**传参约定**

**问题**：参数和返回值都有多种方法，那么，调用一个函数时，具体采用哪种方法，以及哪种方法具体怎么实现？

**传值约定**be被调用者和调用者都遵循的变量和返回值的传递规则，具体怎么约定是随心所欲的。但是标准一旦确定下来，必须在整个项目中遵循，否则就会乱套。

8086约定如下：

![image-20230323110028667](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230323110028667.png)

**问题** 为什么绝大多数调用约定都把参数放在栈上？为什么不使用寄存器传递所有的参数，或者使用变量传递所有的参数呢？

**栈传参** 栈的大小比较大，因此传递的参数可以比较多，准确地讲数量是不受限制的。此外，栈传递参数非常好理解，一般是把当前SP赋给BP，然后将参数列表从右往左依次入栈就可以了。被调用者通过BP指针就可以寻址各个参数，调用完成后要将SP指针恢复到原状也只需要将BP再赋给SP，非常方便。之所以8086的BP寄存器被指定隐含SS段寄存器，就是为了方便栈传参。

**栈框指针** BP叫做栈框指针，因为通过它就能找到与该过程相关的整个调用栈，调用栈包括参数，临时变量，还要返回时的IP

![image-20230323110752601](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230323110752601.png)

**问题** 使用栈传递参数太麻烦了，要保存栈框，还要恢复栈指针。那么，在小型程序中，能否在数据段定义几个变量传递参数呢？ 

**变量传参** 传递参数也可以规定使用变量，比如某几个变量作为过程的输 入，某个变量作为过程的输出。**变量传参适合人类思维**，**因为参数的名称就是变量名，一目了然**。然而，使用固定变量传参的过程是不可重入的，也即一个过程的调用链中不能包含它自 己，因为变量正在被同一个过程的上一个未结束的调用使用。 这等于是说，不能使用任何形式的递归调用。 变量传参在那些程序存储器小、栈操作不便，且架构寄存器少的地方很有用，如8051等经典微控制器。这些架构的链接器会 使用覆盖分析（Overlay Analysis），判断哪些过程不在一条调用链上，并尽量将它们传参使用的变量复用以节约数据存储器。

**问题** 使用栈和变量传递参数非常慢，因为要访问内存。那么，能否彻底避免在传递参数时访问内存呢？ 

**寄存器传参** 传递参数还可以规定使用寄存器，比如某几个寄存器作为过程的输入，某个寄存器作为过程的输出。寄存器传参不需要访问存储器，因此速度很快，但是却需要消耗寄存器。**一旦寄存器用完了，多余的参数就只好通过栈传递了**。因此，在寄存器本来就少的CISC架构上，**寄存器传参往往仅限于前一两个参数。** 



**传参约定选择** 一般程序，**推荐使用栈传递参数**；对速度要求不高的小程序， 以及新手上路，推荐使用**变量传递参数**，这样不容易错，当然 也可以**使用栈传递参数**；对性能要求极高的计算核，推荐使用寄存器（包括向量寄存器在内，它们空间很足）传递参数。

# 3.2 复杂程序的结构

## 一.多个工程共用

### 1.1语言运行时库

### 1.2静态链接库

## 二.多道程序共存

### 2.1简单分区

### 2.2分段与分页

## 三.多道程序共享

### 3.1动态链接库

### 3.2外存的库共享

### 3.3内存的库共享

### 3.4惰性动态链接



# 4.1 处理器调度原理和设计

## 一.指令流与执行

### 1.1应用程序与指令

**指令流** 

一个应用程序内部可以由一个或多个**逻辑上互相独立执行的指令序列**组成。这种独立执行的指令序列叫做**指令流**。CPU靠执行指令流来完成应用程序的功能。

**问题** 为何在一个应用程序里面需要设置多个指令流？

![image-20230321140716064](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321140716064.png)

**计算期与I/O期** 

一个**指令流**往往由**两部分组成**：一部分负责**计算**，另一部分负责**I/O**。两个部分交相点缀，组成一整条指令流。指令流是程序逻辑的组成单位。

在计算机指令流中，**计算期**通常是指处理器执行指令所需的时间，而**I/O期**则是指处理器从输入输出设备读取或写入数据所需的时间

![image-20230321140837174](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321140837174.png)

**问题** 某个指令流可以没有计算期（Burst）吗？可以没有I/O期吗？

 为什么？在一些特殊情况下，可能会不存在其中之一或两者都不存在

指令流中可能不存在计算期的情况通常发生在一些特殊的指令或者操作上，例如NOP指令（No Operation），该指令本身不进行任何计算操作，只是为了消耗一些处理器时间，或者是一些无条件跳转指令，该指令不需要进行计算操作，只需要跳转到目标地址即可。

指令流中可能不存在I/O期的情况通常发生在没有任何输入输出操作的情况下，例如纯计算型任务或者是一些计算机内部的操作，例如缓存操作、分支预测等等，这些操作都不需要从输入输出设备读取或写入数据，因此不需要进行I/O操作。

**指令流的分工** 多个指令流可以分工合作，完成程序的功能。

**按性质分工** 不同的指令流处理不同性质的工作，如一些指令流主要负责I/O， 另一些指令流主要负责计算等等。

**按对象分工** 不同的指令流处理不同部分的工作，如每个指令流负责处理一 部分数据或一个服务对象。

### 1.2顺序与并发执行

**指令流间的执行顺序**一个指令流执行完成后，再去执行另一个指令流。

**优势** 安排工作简单，一件事情做完了再去做另一件事情。

**劣势** 如果一件事情没做完之前，需要暂时放下去做另一件事情的话， 不可能办得到。

**问题** 什么场合可能出现一件事情没做完会被打断？

**需要打断工作的常见情况**

**优先级** 某些任务就是比其它任务更加紧急。如果另一个紧急的任务需 要应用程序立马去处理，当前的任务就必须被打断。

**进行I/O** 相对于CPU，I/O设备的速度是很慢的。一旦开始I/O，当前的指 令流就不占用CPU了。即便让它继续运行，它能做的也只是反复 查询I/O设备的状态寄存器来判断I/O是否完成。

**资源超限** 这个指令流占用了太多CPU时间了，可能达到了某个限额，再放任它继续执行可能造成公平问题，尤其是跨应用程序时：某个 应用程序的指令流将一直占用CPU，其它任何应用程序的指令流 都必须等它结束执行才能得到CPU。

**恶意程序** 某个指令流的唯一工作就是空转（这可能是因为它本身是恶意 程序，或被恶意程序入侵，或出BUG），燃烧CPU时间，并且永 不退出，要等到它退出除非机器烧毁或者停电。

**相互通信** 某些指令流可能依赖其它指令流传递给它的数据才能工作。如 果它无法从另一个指令流那里得到数据，就要一直等待下去， 直到其它指令流返还数据。这在顺序执行模型下是不可能的。



**改进的顺序执行--合作执行** 

将每个指令流**打断成多份**，**每一份之内都顺序执行**，但背靠背 执行的两份**不一定来自同一个指令流**。在每份指令流的末尾， 都**通知操作系统主动放弃CPU**，CPU将转去**执行下一份指令流**。

![image-20230321142128374](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321142128374.png)

合作执行的**特点**：

（1）**交替执行** 指令流在自己执行的途中就可以出让CPU的控制权。

（2）**自愿放弃** 指令流在不需要CPU的时候可以自愿放弃CPU。自愿放弃CPU以 及执行完毕是交还CPU控制权的唯二方法。

（3）**顺序确定** 如果希望，每个指令流都可以在放弃CPU时指明自己希望哪个指令流继承CPU的使用权。当然，如果不指定，那么随机选择一个指令流来运行。

**问题** 合作执行解决了上述常见问题的哪些？

（1）**优先级** 解决了一部分，现在紧急的指令流可以在份与份之间插入了。 但是没办法在份与份之间插入。

（2）**进行I/O**  仅考虑CPU效率，完全解决，指令流只要进入I/O就放弃CPU。

（3）**资源超限** 应用程序的某一段一直不放弃CPU的话，还是拿它没办法。

（4）**恶意程序** 同上，挖矿程序肯定不会放弃CPU，不然它还挖什么矿。

（5）**互相通信** 完全解决，指令流只要在等待其它指令流的回复就放弃CPU。

**顺序执行和合作执行的问题**

（1）**缺乏强制性** 无法强制剥夺指令流的CPU控制权。如果指令流是恶意的，或者 自私的，就没办法对它加以约束了。因此，我们需要一种能够 强制剥夺指令流对CPU控制权的方法。

（2）**并发执行** 将合作执行的条件放宽一点，允许一个指令流在任何时候被打 断，并且新的指令流插入进来。又叫**抢占式执行**。每个指令流 都在自己的虚拟CPU上执行，而且虚拟CPU的先后没法预测。

（3）**细粒度** 每个指令流的每条指令之间都可能被打断。

（4）**不可预测性** 在任何一个指令流被打断后，该指令流无法预测下一个接替它 执行的是哪个指令流。

### 1.3指令流的描述

**指令流的描述**

 在并发执行中，指令流可能**随时被打断**。被打断的指令流的状态信息不能丢失。

这些**状态信息**包括两部分，一部分是**指令流自己的上下文**，另一部分则是**该指令流对CPU的占用状态**。

**上下文** 指令流的上下文包括什么？为什么？

 提示：考虑原理类似的中断上下文。

**寄存器组** 一个指令流的上下文就是足够使其恢复被打断时的状态的内容。 这一般**包括了其寄存器组和执行栈**。在切换指令流时，一个非常方便的做法就是把寄存器组保存在执行栈上，合适时再恢复。

**状态** 一个指令流可以按照它**对CPU的占用状态**分成几类？

（1）**运行** 当前指令流正在运行。

（2）**不运行** 当前指令流不在运行。再细分，不运行可能是因为：

 <1>**就绪** 当前指令流可以运行了，但CPU因为某些原因还没轮到 它，轮到它就可以立马运行。

<2> **阻塞** 当前指令流在等待，就算有空闲CPU也没法运行

![image-20230321143344634](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321143344634.png)

## 二.线程与处理器

### 2.1CPU时间和线程

**处理器时间的分配**

**指令流与时间** 

**操作系统需要给指令流分配CPU时间，然后让指令流拿着这个 CPU时间配额去运行**。但是，指令流是用户程序的逻辑组成部分， 操作系统并不知道用户程序里面有几条指令流。

**线程** 

操作系统提供给应用程序的一种对CPU时间的抽象机制。它是CPU时间分配的基本对象。应用程序通过**将自己的指令流与线程对应起来，使指令流获得CPU时间分配**。操作系统通过运行线程， 来运行依附在这个线程上的指令流。

 也可以说，**指令流通过依附于线程，获得了在CPU上运行的权利**。

**应用程序视角** 在应用程序看来，自己的逻辑组织是**一系列并发执行的指令流**。

**操作系统视角** 在操作系统看来，应用程序的运行组织是**一系列被分配了CPU时 间的线程**。

**问题** 相比于指令流，线程的描述要包括什么数据呢？

### 2.2线程的描述

**线程的描述**

**时间预算** 

**线程是时间分配的基本对象**，那线程必然有一个参数描述它被分配了多少间。这个数值称为时间预算，可以是一个有限的数值，也可以是一个无限的数值。

 操作系统在运行线程时会时刻关注线程的时间预算是否耗尽； 如果耗尽，操作系统就切换到其它有时间预算的线程去执行。

**优先级** 系统中有多个线程同时具备非零的时间预算，如何决定运行哪 一个？因此，线程必须具备一个参数来描述其优先度。当系统遇到多个可以运行的线程时，系统可以决定运行其中优先级最 高的那个。

 优先级一般用一个数值来代表，在绝大多数系统中，**数字越小， 优先级越高。**

 CPU抢占关系实际上是一个偏序集（越紧急的东西，不一定总是越重要；即便是紧急的东西，也不代表它可以不受限制地发生） ，优先级实际上是这个偏序集的一种简化全序描述。不过，这 种描述在很多时候（桌面计算等场合）都够用了。

**问题** 这些数据放在用户程序里面还是操作系统里面？

**线程的上下文**

**上下文** 线程为什么也要有**上下文**？

考虑线程上的执行流因为主动等待 需要操作系统介入的I/O完成或者意外地被外设中断打断而暂停 运行的场合。

**内核阻塞** 操作系统并不知道指令流的存在。因此，在遇到线程上的指令流陷入内核阻塞的时候，内核只能**暂停执行当前这个线程**，切换到别的线程去执行了。更麻烦的是，**线程什么时候陷入内核， 依附在线程上的指令流是不知道的**，也即可能发生抢占。

 一旦一个线程阻塞在内核，对它上面依附的所有指令流来说， 时间就都凝固了。因此，这些指令流都停止运行。

**线程上下文** 和指令流上下文一样，线程的上下文也是其寄存器组。

**线程的状态** 和指令流的状态是类似的，包括**运行、就绪和阻塞**三个状态。

**问题** 线程的上下文和状态放在用户程序里面还是操作系统里面？



**线程控制块(TCB)**

**线程控制块** 操作系统用以描述和管理线程的内核对象，一般至少包含线程的**时间预算、优先级、运行状态及上下文**，有时还会包含一些 **身份信息**（如线程名、线程号）或**统计信息**（如总计CPU时间） 等。它在数据结构上一般是C语言的一个结构体。



 在那些有内核模式的处理器中，**线程控制块位于内核空间**，**只有操作系统可以更改，应用程序无法更改。**

![image-20230321153104507](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321153104507.png)

**线程状态与指令流状态**

**线程的状态** 指令流和线程都有就绪、运行、阻塞这三个状态。那么，这三 个状态和指令流的三个状态有什么区别和联系呢？

**（1）指令流与线程：一对一**

![image-20230321153653664](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321153653664.png)

**优点** 简单。最简单，最好实现，最常见，常见到足以让人把指令流 和线程的概念混淆起来。

**缺点** 每个指令流都成了**单独分配时间**的对象，很多时候不需要这样。 这样会增加操作系统的负担，因为操作系统需要**为每个线程创建一些单独的管理数据**，而且每次**切换当前CPU上的指令流**都需要通知操作系统。

**对应关系** 此时指令流的状态和线程的状态是一对一对应的。**线程处于什么状态，指令流就处于什么状态**。

**（2）指令流与线程：多对一**

![image-20230321153914685](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321153914685.png)

**优点** 高效。同一个线程中的多个指令流可以借由附着在同一个线程上共享一份执行时间，它们在内核中也被当作一个对象来处理， 其TCB仅仅创建一份。对于每一个线程上附着的多个就绪指令流， 应用程序负责决定哪个指令流得到线程从而运行，并切换到它。

 通常而言，只有紧密协作的指令流才会被放在同一个线程上， 而且操作系统并不需要知道指令流的存在，因此仍然可以在那 些一对一的操作系统中实现。

**缺点** 每个指令流都成了单独分配时间的对象，这样会增加操作系统的内存消耗，而且每次切换当前CPU上的指令流都需要通知操作 系统。还有什么额外缺点？ 

**对应关系** 线程处于运行状态，说明其上的指令流中有一个在运行。

 线程处于就绪状态，说明其上的指令流中至少存在一个就绪的。

 线程处于阻塞状态，说明其上的指令流中至少一个发起了需要操作系统介入的阻塞态。

**其它指令流** 状态无法预测，因为只有应用程序才知道它。操作系统是不知 道它们的，因为操作系统感知的只是作为时间分配对象的线程 的状态。线程阻塞了，意味着内核只知道这个时间分配对象上 附着的某个指令流在请求内核完成一个一时半会无法完成的功 能，因此内核能做的就是暂停整个时间分配对象的执行。

**指令流与线程：多对多**

![image-20230321160903041](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321160903041.png)

**原因** 一旦指令**流阻塞在内核**（阻塞在应用程序中则无此问题，因为应用程序 可以自主选择一个新的指令流来使用这个线程），就会阻塞整个线程。 而如果线程上还有能运行的指令流，这些指令流也停止运行。我们自然 不希望这样；然而，每个线程仅提供一个TCB，当前阻塞在内核的指令流 的上下文已经占用这个TCB里面的寄存器组了。

**优点** 那么，我们可以考虑给这些指令流提供多于一个上下文，也就是让多个指令流对应多个线程，**任何一个不阻塞的线程都可以运行任何一个不阻塞的指令流，指令流可以在线程之间迁移**。

**缺点** 臭名昭著地**难以正确实现**。内部细节很多很复杂，这就是灵活的代价。

### 2.3纤程与协程

**纤程与协程：一些额外概念**

**协程(强调合作）** 合作执行的一组指令流。不仅强调它们**不是时间分配的独立对象**（区别 于线程），而且强调**只有其中某个指令流主动放弃CPU时**，其它指令流 才可得到CPU进行运行，并且**放弃CPU的那个指令流还倾向于指定谁来接替它的执行**。

 **实现** 一般地，协程被实现为**在用户模式下的一系列数据结构**，这些 数据结构中**会保存协程的寄存器上下文**。在常见的实现中**协程 对线程都是多对一结构**，因此在用户模式就可以完成互相切换， 无需通知内核，切换的效率远高于线程。

 特别地，对于**无栈协程**（也即那些不使用栈，或者在放弃CPU时能保证栈内不存在有效数据的情况下），它们可以用C语言的 #define配合switch-case实现。

**纤程（强调轻量）** 合作执行的一组指令流。相比于协程，放弃CPU的那个指令流不倾 向于 直接指定接替执行者，而**倾向于唤起一个在用户空间的调度器**，由它来决 定下一个执行的指令流是谁。纤程之间不一定有紧密的合作关系，仅仅 是强调它们比线程要轻量，也即多个纤程共享一个线程。

**比较** 同多于异，几乎是同义词，都是指令流，只不过侧重点不同。

## 三.处理器调度算法

### 3.1调度算法原理

**优先级和时间片**

**问题** 现在有一系列线程在系统中运行。操作系统中的调度器负责决定每次运行哪个线程，运行多久，但又如何决定做这个决定所需的每个线程的优先级和时间片？

**解决方案一** **事先指定**。对于某些系统，我们可以**根据某线程负责运行的指令流的性质**，将某些线程的优先级设置得高一些、时间片设置 的多一些，以体现资源分配的倾向性。整个系统只要按照这种设置来运行就足够完成其功能了。

**优点** **对任务知根知底，且任务固定**时，这就是最好选择。

**缺点** 这要求操作系统**知晓整个计算机体系内的应用程序的性质**，基本上要求应用程序都是同一个团队开发的。更精确地讲，**需要额外信息来进行手动干预**。

**用途** 对于那些**功能简单**，但要求**绝对可靠**的系统，这是一个非常好的办法。它保证了某些指令流具有**绝对的资源优势**，确保那些指令流承担的工作总能按时正确完成。

**例子** 刹车；火箭；飞机；导弹

**固定优先级调度算法**

**固定优先级** **Fixed-Priority，FP**

 所有线程按照事先给定的优先级排序运行。时间片无限长。

![image-20230321171658428](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321171658428.png)

**非抢占式** 调度仅在线程结束时发生，此时从队列里拿出一个优先级最高 的线程运行。

![image-20230321171718270](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321171718270.png)

**抢占式** 调度在线程结束和线程就绪时都发生，此时从队列里拿出一个 优先级最高的线程运行。这等于说，如果有一个新的高优先级 线程加入进来，它会取代当前的任务，立即获得CPU并运行。

![	](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321171739118.png)



**解决方案二** 从应用程序的行为来推测其性质，并且按照某种策略给它分配 优先级和时间片。首先，我们需要一些领导原则，决定我们的 策略的最终目的；第二，这种我们需要一些程序行为的测度， 作为刻画程序行为的手段。

**问题** 领导原则包括哪些？

 提示：考虑多道程序设计的初衷。

**CPU利用率** 前面提过，一个很大的推动力就是保证处理器不会闲着。闲着 就是浪费资源，因为CPU要折旧，而且即便不使用也会耗电。因 此，我们需要保证CPU的利用**效率**。

**系统的响应** 多个程序可能同时竞争CPU。它们都宣称自己最需要CPU来做计 算，而且确实也都会提交一时半会算不完的任务。因此，我们 不能让某个应用程序霸占CPU，而是需要保证多个程序都能分到 一部分CPU来运行自己，保证CPU的利用**公正**。

**问题** 保证**效率**简单，还是保证**公正**简单？

**保证CPU效率** 非常容易，只要确保每次都选择CPU一直在跑某个就绪的线程就 可以了。只要CPU一直在做计算，CPU的效率肯定就是100%。



**公平的常见测度**

**吞吐率**  单位时间内执行完的线程的个数

 如果在某段时间内，执行完成的任务越多，说明CPU分配越普惠， 就越公平。

 假设在时间T内，有N个线程完成执行，就说它的吞吐率为N/T。

**平均等待时间** 线程从就绪态到运行态平均等待的时间

 如果任何一个就绪的线程都越能尽快得到CPU，说明CPU分配的 歧视性成分越低，就越公平。

 假设一共有N个线程，它们从就绪到得到CPU之前必须等W1，...， Wn时间，则平均等待时间为(W1+W2+...+Wn)/N。

**平均周转时间** 线程从就绪态到阻塞或停止态平均花费的时间

 如果任何一个就绪的线程都越能尽快完成其执行，说明CPU分配 的歧视性成分越低、包容性成分越高，就越公平。

 假设一共有N个线程，它们从就绪到得到停止运作分别经过 T1， ... ，Tn时间，则平均等待时间为(T1+T2+...+Tn)/N。

 若设线程的运行时间为Ri，则Ti=Wi+Ri。

**问题** 平均周转时间测度与平均等待时间测度下，公平的具体含义发 生了什么变化？为什么？

**正义的常见测度**

**响应时间** 从用户提交第一个请求到系统做出第一个反馈的时间。

 用户必然希望系统越快做出响应越好，不要拖拖拉拉。**如果响应时间越短，说明执行顺序的安排越符合用户的意图，就越正义**。

**问题** 平均周转时间和响应时间相比有何区别？为何说前者体现了公平，后者体现的则是正义？

 平均周转时间关心一切线程的运行时间，而响应时间仅仅关心 那个用户刚刚提交的线程产生的第一个反馈。前者关心所有线 程，后者只关心某个线程，仅仅是因为那个线程是用户刚刚提 交的，它的响应结果可能是用户正在等待的。

**综合指标** 采用**平均带权周转时间**，其计算式为(T1/C1+T2/C2+...+Tn/Cn)/N。 T/C又叫**响应比**，T/C=1+(W/C)。

响应比 = (等待时间 + 服务时间) / 服务时间 = 1 + (等待时间 / 服务时间)

T表示每个作业的带权周转时间，C表示每个作业的CPU时间或执行时间，

**观察** 对于同样的W，C越小，W/C越大；对于同样的C，W越大，W/C 也越大。一个越短任务的等待时间越长，对这个指标越不利。

 **公平**体现在该式包含了对所有任务的考虑。

 **正义**体现在该式对越短任务的越长等待越不容忍



**公平的极端：先来先服务**

**先来先服务** **First-Come First-Served，FCFS**

 所有任务按照其提交时间排序，提交时间越早的任务优先级越 高，越优先得到CPU。调度仅在任务结束时发生。

**特点** 公平简单有效，对于任务短小且简单的场合这就足够了。

**例** 三个线程E1、E2、E3，参数如下所示，提交给操作系统。

![image-20230321164724555](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321164724555.png)

**问题** E1~E3的等待时间和周转时间各是多少？整个体系的平均时间呢？



**正义的极端：短作业优先**

**短作业优先** **Shortest-(Remaining)Job First，SJF**

 所有任务按照其运行时间排序，运行时间越短的任务优先级越高，越优先得到CPU。调度可在任务结束时和任务提交时发生。

**特点** 响应性好，适合简单的交互式系统。

**例** 三个线程E1、E2、E3，参数如下所示，提交给操作系统。

![image-20230321164910563](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321164910563.png)

**问题** 看上去SJF就是比FCFS好，短作业很快就能得到响应。果真如此？



**调度算法的在线性**

**在线算法** **On-Line Algorithm**

 算法必须在启动后逐个接受输入并即时给出输出。输入并非一 次交给算法的，算法无法预测之后会遇到什么输入。

**问题** 如果在E3执行完成前，用户向系统中提交E4、E5、E6，这些任务 所需要的执行时间都比E3短，那么意味着它们会插队到E3之前。

 如果用户一直提交短作业，那意味着E2将永远得不到执行了。 这和FCFS的情况不同，对于FCFS，后到的作业一定后运行。

![image-20230321165308084](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321165308084.png)

**饥饿现象** 依照某种资源分配策略，**某些请求无限增加时，另一些请求将永远得不到分配**。在CPU调度的问题上，它体现为某些线程将永 远不能获得CPU。

**响应比高优先** **Highest Response Ratio Next，HRRN**

 所有任务按照其响应比排序，**响应比越高的任务优先级越高**， 越优先得到CPU。调度仅在任务结束时发生。是FCFS和SJF的折中， 具备两方优点但又不极端。

 通常而言，调度仅在任务结束时发生。



**交互系统的调度**

**问题** 前面提到的各个算法中，要么使用基于固定优先级的抢占（FP或 者SJF），要么就干脆排排坐吃果果。前者在复杂的场景会导致 饥饿，从而可能导致系统卡死，后者则无法在一个任务开始执 行后将其中途打断。那么，能否有一种算法，不产生饥饿，又 能打断长任务以获得交互能力呢？

**时间片轮转法 Round-Robin，RR（动态优先级）**

 将**每个线程的时间预算切成规模较小的时间片**，每次只运行一 片时间，然后再运行下一个任务。可以看作是**FCFS的一种改进**： 任务先来先执行，但执行时间到就换成下一个任务，等到所有 任务都轮到一遍了，再回到第一个任务执行。

 RR是抢占式的，因为它会**打断超时线程**的执行。

![image-20230321165823366](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321165823366.png)

**特点** 交互性好，所有线程都获得了执行的机会，无论长短；可以保 证在某个时间周期之内，所有的线程都获得至少一次执行机会。

**问题** 时间片的大小怎么决定？长了会怎么样？短了呢？每次每个线程分配到的时间片都必须一样吗？

**时间片轮转法的改进**

**问题** 时间片轮转法无视了进程的固定优先级。如何把固定优先级加 回系统，使其能够做到保证平均CPU获得的基础上，满足某些特 别任务的高优先级需求？

**固定优先级时间片轮转法** **Fixed-Priority** **Round-Robin，FPRR**

 将时间片轮转法进行改进，同一个优先级的任务采取时间片轮 转法，不同优先级的任务之间则采取严格的抢占式固定优先级调度。

![image-20230321171509833](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321171509833.png)

**特点** 非常适合某些小型实时系统。即便在大型系统中，有时候也能 取得不错的性能。最重要的是，在所有效果不错的调度器里面， 它能做到O(1)查询。（调度器的性能为何重要？）

**复杂系统的调度：按线程行为分类**

**问题** 单一的调度算法各有各的缺点。怎么将这些调度算法组合起来， 形成一个综合的算法？

**多级队列** 将线程按类型分成不同的队列，每个队列采用适合自身的调度算法，队列之间又有队列间的调度算法。

![image-20230321171930451](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321171930451.png)

**问题** 同一个线程可能承载不同的指令流；同一个指令流的行为在不 同的执行阶段也可能发生改变。

**多级反馈队列** 在多级队列的基础上，实时动态检测每个线程的行为，并在原 有队列不合适时为其更换到合适的队列。



**层次化调度算法：按线程所在的子系统分类**

**问题** 除了将线程按照自身类别分类，还可以按照什么方法分类？

**层次化调度** 将一个系统分成多个子系统，每个子系统内部有自己的子调度 器并采用适合自身的调度算法，一个父调度器则负责调度多个 子系统。子系统间的时间干扰可以被父调度器加以限制，非常 适合混合关键度（Mixed-Criticality）系统。

 关于层次化调度，我们在实时系统和混合关键度系统的章节再加以涉及。

![image-20230321172220782](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321172220782.png)



**广义的调度算法**

**长期调度** 决定选中哪些**可执行文件**，并将它们装入虚拟内存。

 主要是围绕着**内核对象的创建和虚拟内存的映射。**

 调度的是抽象层次的任务集合，一般对应着一项有实际意义的 工作。

 长期调度一般是用户编写的各类定时执行脚本（Cron Job）或者 用户模式实用程序（Sun Grid Engine）完成的，因为要装入什么 东西只有用户自己知道。

**中期调度** 决定哪些准备好的工作需要实际装入物理内存，哪些装在物理 内存里的工作暂时不执行，因而需要换出来。

 主要是围绕者**页面文件**的扇入和扇出。

 调度的一般是空间保护域，也即进程。

**（短期）调度** 决定哪个装入物理内存的应用程序实例（进程）的**线程**可以得 到CPU来执行。通常指的调度就是短期调度。关于中期调度和长 期调度，我们在讲存储器管理时再来涉及。

### 3.2多处理器与并发

**并发性** 多个指令流依附于多个位于不同物理处理器上线程，做到了多 个指令流的真正同时执行。并发是并行的一种特殊场合，它只 有在多核处理器上才有可能实现。

**并发与并行** 并发是并行的一种具体实现，在并发环境中，不仅并行程序的 各个指令流的指令执行的先后顺序无法预测，而且这些指令流 实现了真正的同时、一齐执行。在单核处理器的并发环境中， 无法实现并行，因为只有一个CPU，不可能同时执行多道程序， 仅仅是交替执行多道程序让它们看上去在同时运行。

 并发和并行**不是一对矛盾概念或者反对概念**，而是**上级和下级**、 **抽象和具体**、**包含和被包含**的关系。如果有人考你并发和并行 有什么区别，那大概是想考查“**是否在多个CPU上同时执行**”这个 考点。

**最终问题** 多处理器调度可能遇到哪些问题？

# 4.2第二节 处理器调度机制和实现

## 一.线程的实现

### 1.1系统线程总览

**系统中的线程总览：按优先级划分**

按照操作系统中的**线程的优先级**，大致可以将它们分为如下五类。

![image-20230321174037511](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321174037511.png)

**输入输出线程** I/O线程必须与硬件打交道。这意味着，它们要对硬件的变动做出即时的响应，因而一般位于极高优先级段，且是实时的。

**例子** 鼠标键盘驱动、网卡驱动、显卡驱动。

**速率限制** 限制驱动程序占用CPU的时间或频次，以防驱动程序占用大量CPU。部分外设会大量生成中断，这将导致系统频繁发生线程  调度和切换（调度和切换都不是免费的），降低CPU的利用率。

 又称为**节流（Throttle）**。后面我们还要回顾这个概念

**系统服务线程** 一系列为应用程序提供必要服务的线程。这些线程承担着重要 的职责，因而一般位于较高优先级段。

**例子** 网络协议栈、文件系统、用户登录服务、远程桌面服务等

**前台程序线程** 当前用户正在交互的应用程序中的线程。它们可能正在等待用 户的输入，或者正需要把输出反馈给用户，因此总是希望它们 能较为优先的得到CPU。但考虑到它们不如系统服务和驱动程序 那样紧急，因此在系统中处于中间优先级位置。

**例子** 文字处理软件、视频游戏、浏览器、即时通信软件等。

**CPU空闲线程** 由操作系统提供的、当CPU确实无事可做时运行的线程。它通常 只做一件事，就是反复将当前处理器置于睡眠态以节约功耗， 它处于最低优先级。

**备注** 在多CPU系统中，每个CPU上都有一个空闲线程。当该CPU无线 程可调度时，就调度它。



**系统中的线程总览：按来源划分**

按照操作系统中的线程的来源，大致可以将它们分为如下三类。

![image-20230321174354805](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321174354805.png)

**驱动程序线程** 驱动程序由设备提供商编写。如果需要安装新的硬件，那么必 须安装适合它的驱动程序。驱动程序线程的运行交给操作系统 管理，用户不能直接管理。

**系统内核线程** 完成操作系统功能所必备的线程，它们运行由操作系统开发商 提供的功能。这些线程对用户而言是透明的。

**应用程序线程** 一般的应用程序的线程，它们运行由应用程序开发商提供的应 用程序中包含的指令流。

**备注** 这个分类不是绝对的。事实上，操作系统一般会自带一些驱动 程序，而驱动程序的发行包中也可能含有应用程序组件。



**系统中的线程总览：按特权划分**

按照操作系统中的线程的特权，大致可以将它们分为如下两类。

![image-20230321174543695](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321174543695.png)

**内核线程** 运行在内核空间的线程；它们运行时，CPU处于内核模式。它 们可以直接访问内核的一切资源。正因如此，它们均由操作系 统内核启动和管理，甚至可以视作是内核的一部分。

 只有可抢占内核有内核线程。后面详讲。

**用户线程** 运行在用户空间的线程；它们运行时，CPU处于用户模式。它们 进入内核的唯一方法是系统调用。常说的线程就是指用户线程。

**概念辨析** “内核线程（Kernel Thread）/用户线程（User Thread）”不要 和“内核级线程（Kernel-Level Thread）/用户级线程（User-Level  Thread）”搞混了，前者是指线程运行时的CPU模式，而后者则 是指操作系统是否知道它们的存在。内核线程和用户线程都是 内核级线程，而所谓的“用户级线程”则是指协程和纤程。

 这两个叫法之所以叫成这样是历史原因。不必深究。

![image-20230321174652090](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230321174652090.png)

### 1.2**线程的实现**

### 1.3上下文切换

**线程的上下文**

为什么线程也有上下文？

考虑线程是的**执行流因为主动等待需要操作系统介入的I/O完成或者意外的被外设中断打断**而暂停运行的场合。

**内核阻塞**

操作系统不知道指令流的存在

**线程与内核栈**

**线程切换流程**



## 二.调度算法实现

### 2.1Linux

**Linux调度器的历史**

（1）单队列调度器   整个系统只有一个运行队列，每次调度时

（2）多队列调度器

（3）O（n）调度器

（4）O（1）调度器

（5）CFS调度器   更公平的调度器，但是数据结构和算法设计稍稍复杂，其时间按发展的实际上是O(logn)

（6）截止期调度器   固定截至期限的任务

（7）现在   能量感知调度，算力感知调度



**操作系统的线程调度：Linux**

调度队列类别：Linux具备如下几个队列，其队列的优先级从高到低分别为：

![image-20230324193211649](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230324193211649.png)

**SCHED_DEADLINE**使用最早截止时间（Earliest Deadline First，EDF） 调度策略执行那些最紧急的任务。

 **SCHED_RR**和**SCHED_FIFO**分别使用固定优先级时间片轮转法（FPRR）和先到先服务法（FCFS）调度那些实时任务。

 **SCHED_NORMAL**、**SCHED_BATCH**和**SCHED_****IDLE**使用完全公平调度**（Completely Fair Scheduler，CFS）**策略调度那些常规任务。

 本课程重点讲CFS。EDF和FPRR的实现留到后面实时系统再讲



**CFS调度器的设计思想**

**虚拟CPU切分** 

每个线程都有一个虚拟CPU，它**完全占有一个CPU**。CFS的核心思想就是**将物理CPU切割为这些虚拟CPU，并且保证这些虚拟CPU 以最精确的粒度齐头并进**，好像一个主频为kN的CPU被切分为k个主频为N的CPU，并且每个CPU分别运行一个线程那样。

**理想运行时间** 

基于虚拟CPU切分的思想，我们为每个线程准备一个理想运行时 间（Ri）变量。随着实际时间（wall clock time）的增长，Ri也自 动按比例增长。假设系统中有10个任务，且在现实中已经过去 10秒，则每个任务应得的Ri都各增加1秒。

**虚拟运行时间** 

同时，我们为每个线程维护一个虚拟运行时间（Rv）变量。 该变量记载线程实际上得到了多少CPU。

**运行时间差值** 

定义运行时间差值Rd=Ri-Rv。

**调度决定** 

基于Rd，在每次调度时都调度**Rd最大**的那个线程并给予它一定的 CPU运行期。这样就保证了当前最饥饿的那个线程总是被先调8520度。

### 2.2windows

### 2.3MacOS



## 三.系统线程接口

### 3.1线程的基本操作

### 3.2线程接口实例

# 5.1空间的协调—主存储器（内存管理）

## 一，内存的分配

### 1.1程序内的分配

分段——程序再执行时的虚拟地址布局是分段的

.text/.rodata/.rwdata/.zidata——存放各个大小固定的段，分配时是已知的

.stack——分配也是已知的，而且这个段一般比较小

.heap——最大的段，程序中所有的内存分配请求都在这一段进行

![image-20230418162254664](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418162254664.png)

应用程序内部——指令流的分工

1. 按性质分工。不同指令流处理不同性质的工作，如一些指令流主要负责I/O，另一些负责计算等。
2. 按对象分工。不同指令流处理不同部分的工作，如每个指令流负责处理一部分数据或一个服务对象

**动态内存分配**

原因：

1. **功能性质的不确定性**——很多应用程序有很多功能，但**用户这次要用哪个功能它不知道**。因此，它必须等待用户的决定才能加载那个功能对应的数据。当然，也可以在应用程序启动时加载一切功能，但那些用不到的功能就造成空间浪费。
2. **工作阶段的不确定性**——哪怕对于同一个功能，在**不同的工作阶段，它需要的内存的数量也是不同的**。当然，也可以直接按照最大用量阶段的内存用量进行分配，但此时就会造成空间浪费。
3. **服务对象的不确定性**——即便在同一个工作阶段，**如果该阶段针对的对象的大小不同，为了容纳这些对象，使用的内存的数量也会不同。** 当然，也可以直接按照最大的对象来分配内存，但对于较小的对象而言这将造成空间浪费。

**动静态对比**：相对于静态内存分配，动态内存分配最大的特点就是其动态性。动态性是为了再不确定的情况下节约内存而引入的，如果一台计算机的内存是无限大的，或者工作性质，工作阶段，服务对象是完全正确的，不需要动态内存分配。

**动态内存分配请求的生命周期**

分配——>使用——>释放

分配——应用程序的某个指令流发出一个**从堆中申请内存的请求**。堆的大小是已知的， 某个应用程序内部的分配算法将从堆切出一部分内存并返回给这个请求。

 C语言的**malloc、calloc**等函数会从堆中申请内存。

使用——应用程序中的某个或某些指令流持有该内存块一段时间。在这段时间里，它们可能会读写该块内存。

释放——指令流不再使用这个内存块，并将其**归还回堆中**供以后申请。

 C语言的**free**函数将会释放内存，将内存归还给堆。

**C语言接口回顾**

**malloc** 在堆上申请一段内存空间。

 **函数原型** void* malloc(size_t size)

 **参数** size_t size - 要分配的内存的大小。

 **返回值** void* - 指向新分配的内存的指针。

 

**calloc** 在堆上申请一段内存空间并清零。

 语义相当于先malloc(nitems*size)大小的空间，再memset为0。

 **函数原型** void* calloc(size_t nitems, size_t size)

 **参数** size_t nitems - 要分配的对象的个数。

 size_t size - 每个对象的大小。

 **返回值** void* - 指向新分配的内存的指针。



**free** 归还由malloc申请的内存空间。

 **函数原型** void free(void* ptr)

 **参数** void* ptr - 由malloc或calloc返回的指针。

 **返回值** 无。



**如何分配堆中内存？**

目的：保障分配的效率，不浪费内存

1. 离线分配法——如果直到每次请求的大小以及分配和释放的时间，原则上就可以设计除一个算法，可以用最小的堆来满足分配

   问题一：假设太强，事实上不可预知

   问题二：即便大小和时间已知，这个离线动态分配问题是一个NP问题（解可以在多项式时间内检验，归约到图的顶点着色问题）

   这个分配方法存在的意义：是一个值得追求的理想。。。。

2. 在线算法

   **竞争比**——对于某种测量结果好坏的负向指标S（S越大越不利），对于任何一个输入集K中的具体输入k，如果一个在线算法ALG其输出的解的指标SALG与解决同样的问题的最优离线算法的解的指标SOPT相 比恶化最多N倍，则称该在线算法的竞争比为N。

   $$∀k∈K，S_{ALG} (k)≤N×S_{OPT} (k)$$

   这个算法反映了某个在线算法为了在线输入的不确定性而付出的代价。一个好的在线算法拥有较低的竞争比，这意味着它深谋远虑，为未来的可能性留足了风险管理空间，因而在不确定性方面付出的代价小。

   **内存分配** 

   对于内存分配问题，这个指标S可以定义为**满足某种分配的堆大小**。因此，对于同样一个分配-释放序列，算法的质量越差，需要的堆就越大，这个指标就越小。

   或者说，对于需要的最小堆大小不同的内存分配算法，需要堆越多的那个算法对堆空间的利用越低效、浪费越多，竞争比也 就越差，越没有竞争力。

   

**程序内的分配策略**

**固定分区法**——对空间划分为多个大小相等的内存块，每次分配内存的是偶都分配固定的一块空间。（仅适合最简单的应用程序）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418171303707.png" alt="image-20230418171303707" style="zoom:67%;" />

碎片——出于某些原因，无法有效利用而被浪费掉的资源。

​               在这里是出于内存分配策略被浪费掉的内存空间。

内部碎片——**实际上已经指派给某个分配，但是逻辑上无法被这个分配利用的资源**。这通常是由于分配粒度导致						的；如果实际分配的粒度 和分配请求的粒度不一致，每次分配的资源数目要向上取整到 分配请求的						粒度，造成浪费。这些因为取整而额外多出来的内 存就是内部内存碎片。

 					   如果分配的粒度与请求的粒度是一致的，不存在内部碎片。

外部碎片—— **尚未被实际分配出去，但因为某些逻辑上的原因无法分配的资源。**这通常是由于资源请求的空间分布限制与实际资源的空间分布方式冲突致的。最常见的冲突是请求的连续性与资源分布 的不连续之间的冲突，在内存分配问题上尤其如此。如果某些资源在空间上不连续，即便总量足够，也无法满足连续分配的需求。



**多固定块法**——在单固定块的基础上修改一下，维持多个内存块池。每次动态分配的时候，从最接近的能满足大小的内存池中分配一整块。（仅适合简单的应用程序）

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418171641707.png" alt="image-20230418171641707" style="zoom:67%;" />



**动态分区法**——**将整个堆切成与某个粒度相同的小块**，粒度由所有分配的最大公约数决定。**每次分配都分配一个或连续的多个小块。**作为一个特例，如果每个小块的大小都是1字节，那么对任何分配而言都不会产生内部碎片。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418172104567.png" alt="image-20230418172104567" style="zoom:67%;" />



**首次适配法（First-Fit）**——在空闲区列表中**按某个线性顺序**（最常见的是空闲区的地址序，也可以是各个空闲区在列表中的登记顺序或者从上次分配的位置开始依次往后）**检索**，**第一个能容纳该分配的空闲区被选中**

优点：简单，对大小内存申请都公平，没有倾向性

缺点：不试着**保留大的整块区间**，也**不试图规避碎片**



**最好适配法（Best-Fit）**——遍历空闲区列表，选择能容纳该分配的空闲区中的**最小的那个**

优点：**试图推迟对大空闲区的分割**以便将其用于未来的整块分配，直到不得不分割它们。倾向于大块整块内存分配。

缺点：这么做等于劫小济大，会让小的空闲区碎的更厉害。一旦小的空闲 区都碎到不能再碎而无法完成分配，大的空闲区也要遭殃



**最坏适配法（Worst-Fit）**——遍历空闲区列表，选择空闲区中的**最大的那个**。

优点：试图**推迟难以用于任何分配的极小碎片的产生**以便保持内存对于一般分配的可用性。倾向于小块碎块内存分配。

缺点：这么做等于劫大济小，很快就不会有大块的空闲区剩下了。如果程序此时要分配大空闲区，那基本就分配不了。



内存分配策略的共性问题

1. 每次分配都遍历空闲列表。

   有多少空闲区，就要花多少时间， 这个时间是O(n)的。次次这样哪个应用程序都受不了这个时间开销， 尤其是运行得越久内存就越零碎，这个n就越大。

2. 策略单一

   试图将所有内存都塞在一个内存池里面。这是非常幼稚的做法；就像线程调度那样，不同指令流的内存分配倾向也可能不同。有些指令流倾向于分配大的整块内存，有的则倾向于分配小的碎块内存。 将它们的分配放在一起的结果就是互相干扰：小块内存的分配导致大块内存因为空间不连续分配不了，大块内存的分配导致小块内存 因为空间不够分配不了。

3. 粒度过细

   在最极端的实现中，连1个字节也可以作为空闲区挂在空闲区列表 里面等待分配。这理论上当然消灭了所有内部碎片；然而，空闲区列表以及空闲区数据结构也都不是免费的。为了一个1字节的空闲区，花费数十字节的额外数据结构为它做登记，这个代价未免过于昂贵。

   

### 1.2程序间的分配

程序间分配的问题

1. 过度分配

   某些程序为了堆声明过大的空间或者不知道要声明多少空间，如果分配多了就会浪费，造成内部碎片，分配少了，就不够用。

2. 内部碎片

   这里指的是操 作系统已经指派给程序，但逻辑上无法被这个程序利用的内存。

3. 外部碎片

   有可能出现操作系统仍有内存但因为某些原因无法分配给应用程序的情况，比如内存不连续。

   这只有在简单分区或者段式内存管理单元上才会出现；对于页式内存管理单元这是不可能的， 除非用户请求超级页。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418174502471.png" alt="image-20230418174502471" style="zoom:67%;" />





## 二，进程与内存隔离

### 2.1 虚拟地址

**简单分区**——将物理内存切割成几个块，一个块运行一个应用程序，或者放置一个应用程序的某个段。各个应用程序的各个段在链接时就决定好要放置在什么地方。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418174700044.png" alt="image-20230418174700044" style="zoom:50%;" />

**虚拟地址空间（翻译+隔离）**

**硬件地址翻译** 采用添加额外硬件的方法，将应用程序发起的**存储器访问的地址做系统性翻译**，使得**不同应用程序中对一个地址发起的访问实际对应内存总线上的不同地址**。

**虚拟地址** 应用程序认为它自己在访问的地址。也叫**逻辑地址。**

**物理地址** CPU实际送出到内存总线上的物理存储单元地址。也叫**实地址。**

**XX地址空间** 由XX地址组成的地址集合就叫做XX地址空间。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418174758327.png" alt="image-20230418174758327" style="zoom:50%;" />



### 2.2进程的描述

**进程Process**——操作系统提供给应用程序的一种对**地址空间**的抽象机制。**它是内存分配的基本对象**。应用程序通过将自己装入地址空间与进程对应起来，使自己在内存中拥有一个活动副本。**操作系统通过给进程分配内存，来给依附在这个进程上的应用程序提供运行空间。**

 也可以说，**程序通过依附于进程，获得了占用内存空间的权利。**



**地址空间和进程**

就和**指令流与线程**的关系类似，操作系统并不直接知道某个应用程序的存在，它只能看到某些程序通过某些方法向某个地址空间加载数据并在那里执行。只要用户愿意，且应用程序的设计许可，用户可以在一个地址空间中装入多个应用程序，也可以将一个应用程序分成多个互相协作的地址空间。



**描述符标**：进程本身是一个地址空间，所以必然有一个参数描述这个地址空间，它一般是一个表格，足以令操作系统决定哪些内存该进程有权访问，以及怎么访问

注：地址空间未必是虚拟地址空间。在经由物理地址空间的处理器上，如果具备内存保护单元也是可以实现进程的，因为他能实现隔离，但是这样就无法实现地址翻译了，需要自行解决应用程序之间的地址冲突问题

进程还可以包含一些其它权限描述，比如对文件、设备等的访问权限。



更本质的定义

**进程**是一种**特殊的保护域**，其特殊在它是常见保护域中最小的一种且经常与地址空间联动。

（**保护域（Protection Domain）**是一组**权能（Capability）**的集合，又 称为**权能空间（Capability Space）**。这些权能一方面**赋予（Grant）** 进程合法资源操作的权限，另一方面**限制（Confine）**进程非法操作 资源的企图，最终实现保护域之间的**隔离（Isolation）**，**权能**  一种代表对某种资源做某种操作的许可的不可伪造（Unforgeable）  的令牌（Token），保护域获得它的唯一方式是等待管理者为其下发。容器，虚拟机都可以看作保护域）

 进程持有的地址空间描述符表可以看做是对**地址空间的访问权能**， 其它权限则可以看做是对其他资源的访问权能。不管如何，这些权能都只能由更高层次的管理者（如操作系统或其它高权限进程）下发。

**进程控制块PCB**

操作系统用以描述和管理进程的内核对象，一般至少包含进程的**地址空间描述符表及一些其他权限表**，有时还会包含一些**身份信息（如进程名、进程号）、统计信息（如当前正在运行的线程数、总计内存大小）、线程信息（当前的线程列表，内含指向各个TCB的指针）**等。它在一般是C语言的一个结构体。

进程控制块总是**位于内核空间**，只有操作系统可以更改，应用程序无法更改。与TCB不同，没有内核模式的CPU不需要也无法 （用硬件手段）实现PCB

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418191431188.png" alt="image-20230418191431188" style="zoom:50%;" />

**进程与可执行文件**

1. 可执行文件——应用程序在外存上的存储方式。它描述了应该为应用程序建立一个什么样的进程，进程中要有什么样线程，以及线程和具体的指令如何对应。它是死的，干瘪的，静态的应用程序，没有执行环境和上下文，内有执行活动。

2. 进程——应用程序在内存中的活动组织，它是活的，丰满的动态的应用程序，具备一个由地址空间和其他权限提供的执行环境，并充满了线程的执行活动和上下文

3. 关系——可执行文件对进程为一对多关系。一个可执行文件每启动一次就可以创建一个（这是通常的实现）或一组进程；如果它启动多次，就可以创建一系列或一系列组进程。

   同一个可执行文件，在启动为不同的进程时，可以处理不同的工作、 使用不同的权限，或者以不同用户的名义启动。生成的多个进程之间是不同的，因为他们内部的执行环境、执行活动和内部线程的上下文均有差别。





**进程和线程**

线程通过在进程内运行，将CPU时间转化为地址空间的一个访问操作次序

线程——CPU执行时间的分配对象，指令流通过依附于它获得执行时间。但它又需要依附在进程上获得执行空间

进程——仅仅一个执行空间，本身不具备执行能力。作为特例，一个进程在创建时可以不包含线程，而是等待其他进程中的线程迁移过来。

关系——一对一、一对多、多对一、多对多关系，它们在数量上没有任何固定的对应关系

**一对一关系**：最常见关系，在Linux2.4前，线程和进程是一个东西，task_struct里面包含线程的信息和地址空间的信息。

**一对多关系**：常见的关系，一个进程中同时存在几个线程，多线程进程，

本质是多个CPU时间分配对象共享一个内存空间分配对象

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418193006088.png" alt="image-20230418193006088" style="zoom:50%;" />

**多对一关系**：罕见的关系，线程可以被称为迁移线程，它会在多个进程之间（以受控的方式）游走，在不同的执行阶段使用不同的地址空间和权限，但始终使用同一份CPU时间预算。<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418193315949.png" alt="image-20230418193315949" style="zoom:50%;" />

**多对多关系**：<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418193423704.png" alt="image-20230418193423704" style="zoom:50%;" />



### 2.3内存隔离机制

内存隔离机制：**分段**，按段划分虚拟地址

**段式内存管理单元（S-MMU）**

常用于分段布局的存储器访问管理工具，具备**按段地址重映射**和**访问权限管理**两个职能。

段式内存管理单元使用一张**段表**，每段都包括“**段号**”，“**段物理地址范围**”和“**段权限**”三个部分、

应用程序访问发起每一次内存访问都需要经过段表的转换和检查

1. 按照访问的拘泥地址中的段号信息查找相应的段
2. 发起的访问的性质必须式该段的权限允许的
3. 访问的物理地址=段基址+虚拟地址，且虚拟地址不得超过段长度

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418195613719.png" alt="image-20230418195613719" style="zoom:67%;" />

**段表的查询**

段表放在CPU专用寄存器，进程切换时，需要从PCB取出新进程的段表，然后拷贝到CPU专用寄存器中。这种是简单的情况，很多是一系列寄存器组

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418200756494.png" alt="image-20230418200756494" style="zoom:80%;" />

优点：段的描述是存放在CPU寄存器中的。CPU在生成物理地址时只要查询这些内部寄存器就可以，无序额外访问

缺点：无法直接支持比CPU的段寄存器组数量还多的段，因为段寄存器的数量时在设计CPU时就决定了的。

解决方案：将段表存储在内存中。每次内存访问，需要先查询在内存中放置的段表，然后再根据该表项的内容计算真实的物理地址。CPU只提供寄存器来指向段表在内存中的物理地址。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230418201404504.png" alt="image-20230418201404504" style="zoom:80%;" />

优点：能支持无限目的段，段表放在内存中，大小几乎是无限的

缺点：每次访存都膨胀成两次，首先访问段表，然后再访问内存本身，现代CPU的访存延迟都很高，这势必造成严重的性能损失，尤其当段表也不在数据缓存中的时候。





## 三，内存的活用

### 3.1请求分页

### 3.2替换算法

### 3.3内存映射



# 5.2 空间的协调—进程实现（主存储器分配机制和实现）

# 6.1空间的协调—外存储器（外存管理）

## 一.外存的特点

外存和内存的区别？

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421190121135.png" alt="image-20230421190121135" style="zoom:80%;" />

外存——**最本质特征**就是**无法通过访存指令直接访问**，其他的特征都是辅助特征，，一个存储器是否是外存，不取决于存储器的物理属性，而是它在计算机架构中的访问属性

外存一般是只能**按块访问**、**不能高效随机访问的**。这是因为它们往往需要将容量做得很大，为缩减成本，在研发时就牺牲了其随机访问的能力。同时，很多资料需要永久保存，因此外存往往还是非易失的。这进一步牺牲了外存的访问速度和延迟， 使其性能全面落后于内存。

外存的特点：

1. 可靠性

   相较内存而言，外存需要跨上电周期**长时间储存数据**，因此其可靠性更加重要。很多外存技术为了容量极大地牺牲了原生物理存储单元的可靠性，因此需要**软件纠错措施**加以补强。

2. 保持时间

   外存能够在机器掉电后保持内容不变，但这种能力并非无限的。对于那些储存电荷的外存，一旦失去电力，其**数据便开始退化**，**在一段时间后便无法读写**。其它原理的外存往往也会由于介质的**逐渐劣化而影响数据的完整性**。

   准确地讲，在随时间劣化的是可靠性，保持时间仅仅是可靠性劣化速度的一个体现。当存储单元的可靠性恶化到无法靠软件纠错来补救，保持时间也就到头了。

    保持时间和可靠性在实践中受非常多因素影响，包括访问的累计次数、环境温度、介质工作模式等等。

3. 可擦写性

   部分外存介质如只读光盘等是不能够反复擦写的。它们只能接受一次写入，而后其内容便不可更改。当然，也存在可以反复擦写的光盘。常见的外存如硬盘等都是可以反复擦写的

4. 可覆写性

   部分外存介质可以反复擦写，但是却**无法直接在已经写有内容的介质上直接覆盖写入新内容**。要复用已经写入过的介质，必须要执行**擦除**操作，该操作会清空一整片介质上的旧内容，然后这片介质才能接受新的写入。

5. 访问粒度

   **外存的读（Read）、写（Write/Program）和擦除（Erase）粒度是相互独立的三个参数**，它们都可以是字节或（大小不等的）块。比如，完全可能存在某种外存介质，它可以接受以字节读取，但必须按块写入，而擦除时则只接受全盘擦除。

6. 访问寿命（耐久性）

   **外存的读、写和擦除寿命也是相互独立的三个参数。**它们都标志着对其存储单元进行多少次相应操作后存储单元即告报废。绝大多数外存介质的读寿命都是无限长的，但其写寿命和擦除**（耐久性）** 寿命则是有限的。一次写入/擦除操作称为一个循环，又称一次 P/E。我们经常用P/E数来衡量外存介质的寿命。

7. 访问延迟

   因外存介质的物理组织较为复杂，其**不同地址存储单元的访问延迟差别很大**，且该延迟与访问顺序可能存在很大关系。此外，读、写和擦除的延迟可以不同，而且差距还可以很大。

外存的内存化

随着技术发展，外存技术逐渐摆脱了不能随机访问、无法覆写、 耐久性差的传统印象。以FRAM和PCRAM为代表的外存技术逐渐可以在各项性能上与内存相媲美，同时拥有近乎无限的P/E数。 因此，这些技术逐渐衍生出可以直接插入内存插槽的形式，并可以当作系统内存使用。

内存的外存化

在DRAM上加上后备电池或者闪存，它就可以持久保存内容，此时称为NV（Non-Volatile）DRAM；再将它挂载到外存总线上，它就可以充当快速的外存。在SSD出现以前，这是非常常用的实现高速外存的手段。直到今天，这种手段仍在数据中心和加速器等场合有用武之地。



## 二.数据和文件系统

### 2.1文件的概念

分类：

1. 文本文件——由字符组成的文件，可以用文本编辑器打开
2. 二进制文件——由无约束二进制字节流组成的文件，用文本编辑器打开会乱码

定义：

文件——一个具备一些**属性**的数据记录。我们可以根据其属性对相对应的数据记录进行**增（Create）删（Delete）改（Update）查 （Read；合称CRUD）**。它一般需要被**永久保存**，因而存储在非易失性**外存**上；可以看作是对外存的一种组织和抽象。

属性——文件的属性一般至少包括**文件名**，有时还包括**文件大小、 创建日期、修改日期、文件权限、所有者**等内容。除文件名外，它们一般都被储存在**文件控制块（File Control Block，FCB）**中

逻辑结构：

1. 字节流结构——最基本的结构，提供一个连续的存储空间，可以放置数据
2. 记录结构——提供一个固定大小的存储空间，可以放置大小固定的数据块
3. 索引结构——提供键值对，键—>值

物理结构——文件在外存上的物理保存形式，由多个中间映射层负责决定。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421193117974.png" alt="image-20230421193117974" style="zoom:80%;" />



### 2.2	文件系统的概念

定义：

文件系统：

将文件中的**文件块**按照一定的方法最终**映射**到物理设备上的**物理块**，并在物理存储器特性的限制下**提供尽可能高的信息管理效率**。提供这种功能的**软件栈**称为文件系统。一般地，它**提供按名称和路径访问文件的功能。**

 广义的文件系统包括这个映射中的所有层次。狭义的文件系统仅仅指从文件映射到逻辑设备这一个层次。



能不能将文件系统看成数据库？？

不能，文件系统更底层，更原始，提供的功能少，侧重数据的存储而不是查询，键值存储

关系型数据库则在文件系统的基础上提供更多数据抽象、数据查询、数据去重、数据统计、并发控制、 故障恢复、权限控制等功能，可以看做是文件系统的升级版。



**逻辑设备**——**逻辑上**存在的**外存设备**。它可能是一个或数个物理外存设备按照某种方法拆分或组合产生的设备，内部的块称为逻辑块 （Logical Block）

区分——物理存储器按块号**分成**多个连续的逻辑存储器

阵列——将物理存储器按照一定规则**整合**到一个逻辑存储器

**物理设备**——实际存在的存储硬件设备

**物理介质**——物理设备中包含的实际存储介质



**块的映射**

早期：外存和内存**区别不大**，接入系统中的存储器**是磁芯存储器和磁泡存储器**，它同时具备**非易失性和随机访问的能力**；其它存储器包括打孔卡片、纸带等需要人工装入计算机，它们可以看作是最早的外存。此时，访问任何一个文件块地址就是访问存储介质的物理块地址，因为**一个物理存储介质上只存储一个文件**。

容量的增大：随着磁盘容量的进一步增大，**制造完美无瑕的存储介质变得不可能**。一片物理磁盘中，总有几个地方是有缺陷的，无法存储数据，这些缺陷称为**坏块**。然而，**存储设备必须给操作系统呈现连续而完美的设备存储空间**，因此要引入地址重映射的办法将这些**坏块屏蔽**掉。

在现代SSD中，**从设备块到物理块的翻译**由**闪存翻译层**（Flash  Translation Layer，FTL）负责，它兼具**坏块屏蔽、磨损均衡和存储空间整理**等作用。

灵活性的提升：

随着硬盘容量的进一步增加，对硬盘管理的灵活性也在提升。 有时，我们希望**将硬盘分成多个区域**，每个区域负责一种或一 类用途，每个区域可以单独备份、迁移和管理；另一些时候， 我们希望**将多块硬盘组合成一个大的存储池**，用来承载单块硬盘难以承载的数据量，或者提高存储的可靠性。

 此时便出现了逻辑设备的概念：它和物理设备之间可以是**一对 一、一对多、多对一或多对多**。在现代云计算中，存储层次更复杂，对存储灵活性的要求更高，甚至要求存储器的热插拔和程序的热迁移，因此逻辑设备与物理设备之间的映射越发复杂

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421201024217.png" alt="image-20230421201024217" style="zoom:67%;" />

**路径和目录**

文件系统一般以**树状**的方式组织文件

路径——文件在文件系统中的位置用**路径**表示。路径字符串由**一系列由分隔符隔开的子字符串组成**，它唯一确定一个文件。路径又可 以分为绝对路径和相对路径。分隔符一般是“/”或者“\”

目录——文件路径中由分隔符隔开的子字符串，又称文件夹。每一个目录都对应于一个文件组织层次。目录可以互相嵌套，一个目录下的其它目录称为它的子目录。

相对路径——从**某个目录D起始**，经由逐步查找能找到某文件F的路径，称为F相对于D的路径

绝对路径——某文件F相对于**系统根目录**的路径。也即从系统根目录出发，一步步跟随查找，能找到该文件F。

工作目录——某**应用程序**进行文件路径解析的**起始目录**。该程序中的一切路径都看做是对该目录的相对路径。

 	

特殊目录——为了让**姐妹关系的目录**也能**使用相对路径进行互相引用**，每个目录下都设置两个子目录，它们是文件系统自动创建的。

- **目录“ . ”** **当前目录**。这在一些需要指定某路径为当前目录的场合特别有用，比如指定程序的工作目录为当前目录就可以写“./”。
-  **目录“ .. ”** 当前目录的**父目录**。引用这个目录就等于回到 当前目录的父目录。



### 2.3文件系统的组织

文件系统的性能指标：（只考虑文件系统—物理介质两个层次）

| **性能指标**   | **评价方式**                     |
| -------------- | -------------------------------- |
| 连续读取       | MB/s，带宽                       |
| 随机读取       | IO/s，操作数量，或者ms，响应延迟 |
| 连续写入       | MB/s，带宽                       |
| 随机写入       | IO/s，操作数量，或者ms，响应延迟 |
| 覆盖修改       | MB/s，带宽                       |
| 增加修改       | MB/s，带宽                       |
| 按名称查询文件 | ms，响应延迟                     |
| 按内容查询文件 | ms，响应延迟                     |
| 文件内寻址     | ms，响应延迟                     |
| 存储使用率     | %，百分比                        |
| 故障容错性     | N/A                              |

文件的存储：

**1. 连续分配法**

定义：将文件一个接一个的放置在外存上**，每个文件占据连续的物理介质块**

FCB只记录文件的起始块号和长度，就能唯一确定一个文件

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421203454149.png" alt="image-20230421203454149" style="zoom:50%;" />

优点：顺序和随机读写速度都快，不会出现内部碎片，管理数据结构短小精悍，存储介质利用率高，存储介质损坏只影响部分数据，数据可靠性高。

缺点：文件长度难以随意追加，可能存在外部碎片

适用场合：数据备份和归档等倾向于单次写多次读（Write Once Read Many， WORM）的场合。典型例子是用于LTO磁带的线性磁带文件系统 （Linear Tape File System，LTFS）

**2. 链接分配法**

定义：按照某个固定的块大小分配文件，每个块内部放置一个指针，指向下一个块。如果没有后续块，使用空指针。

FCB中只要记录文件的起始块号就能顺藤摸瓜找到整个文件；也可以说每个文件对应了一条块链。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421204833617.png" alt="image-20230421204833617" style="zoom:50%;" />

优点：文件长度可以随意增加，不会产生外部碎片

缺点：顺序读写慢，随机读写更慢，管理数据结构包含指针，指针本身消耗存储介质，存储介质破坏，会导致指针丢失，所以数据的可靠性差。

问题：	分配块的大小的选择？



**3. 链接分配法的改进**

连续分配和链式分配的折中。

利用链表来避免外部碎片，利用可变长度块来避免内部碎片，

可变长度块称为**扩展**，内部包含指向下一个扩展的指针以及本扩展的长度，

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421213117775.png" alt="image-20230421213117775" style="zoom:50%;" />

优点：文件长度可以随意增减，不会产生外部碎片，同时扩展的大小灵活，也不会产生内部碎片。

缺点：顺序读写有一定提升，随机读写还是慢，管理数据结构包含指针和扩展长度，在存储碎片化严重时候可能进一步消耗存储介质，存储介质破坏，会导致指针丢失，所以数据的可靠性差。

应用场景：这种文件系统是实用的最简单文件系统，其典型代表为exFAT。 exFAT支持按照固定块进行链表分配，也支持将整个文件放在一 个扩展中。但它不允许将整个文件分成两个或更多扩展。

**4. 链接分配法的继续改进**

链表备份——不将指针和扩展长度和文件结构存储在一起，而是分开，给他们单独的存储空间

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421213606982.png" alt="image-20230421213606982" style="zoom:50%;" />

优点：管理结构就和数据分开，只需要单独备份管理信息就可以，管理结构中包含所有文件的所有块的组织信息，而且本身短小精悍，可以在盘上保存多个备份，只要还有一份管理信息在，整个文件系统就没有受结构性破坏，抗损性强，数据区受损只会引起数据损坏，不会导致文件系统崩溃。

随机访问提速 ：小巧的管理结构可以被单独加载进内存。这样，随机寻址虽然 还是要做指针追逐，但是在内存中追逐指针速度要快得多。

**5.索引分配法**

索引分配——给每个文件创建一个线性索引表，每个表项记载对应于该逻辑块的物理块

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421214842136.png" alt="image-20230421214842136" style="zoom:50%;" />

优点：连续和随机访问都快，抗损性能也强，、

确定：索引预留多了，浪费，索引预留少了，文件大小受限

**6.索引分配的改进**

**多级索引**——像组织页表，将多个索引表以层次的形式组织起来，每个层次负责翻译逻辑块号的一部分，最终得到物理块号，不使用的索引就不创建，不填充，虽然随机访问仍然引起指针追逐， 但是追逐的次数是有限的，也即索引的层数。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421220022775.png" alt="image-20230421220022775" style="zoom:50%;" />

解决给文件预留多少索引的问题

稀疏文件——有一些文件仅占用整个逻辑空间中的几个很分散的逻辑块，而其 它块都是0。索引分配法可以轻松应对这种情况：不为那些全0的 逻辑块填充索引，也不为它们分配空间即可。

应用场景—— 除exFAT这种需要和极其古老的链式分配的FAT兼容的文件系统之外， 绝大多数现代文件系统都采取多级索引分配法。



**7.索引分配法的继续改进**

**混合索引**——文件的索引采取多级方法进行，但索引的级数随着文件块号的增加而增加。文件越靠前的部分，索引的级别越少。这样，小文件的存储效率就提高了

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230421220036191.png" alt="image-20230421220036191" style="zoom:50%;" />



**8.混合索引法的继续改进**

直接内容法——文件非常小的时候，允许将文件内容直接记录再FCB中

从连续存储法的视角出发，这可以看作是连续存储法的一种应用；从索引存储 法的视角出发，这可以看作是“零级索引”，它们的内容直接就是文件内容。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423161422028.png" alt="image-20230423161422028" style="zoom:50%;" />



**空闲块**——文件系统中暂时未被占用的物理块

怎么处理空闲块？

连续存储——将所有空闲块的地址和长度存储在表格中

链表存储——将所有空闲块放在链表中

索引存储——将所有空闲块放到多级索引中

| **存储方式** | **优点**                                                     | **缺点**                                                     |
| ------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 连续存储     | 简单好实现，空闲块及其范围一目了然。分配和释放可以照内存分配的办法操作。 | 空闲块列表需要额外的空间来存储，而且该列表的大小是固定的，必须能够放下所有的物理块。 |
| 链表存储     | 相对而言也比较简单，分配单个块很容易。                       | 分配和释放大量块时候会导致大量磁盘读写；找连续的扩展很麻烦。 |
| 索引存储     | 在分配单个块较容易的基础上，分配和释放大量块比较高效，因为索引表可以一次填充很多。 | 分配单个块需要做多级指针追逐。此外，结构复杂，找连续的扩展时候仍然很麻烦。 |

















## 三.虚拟文件系统

# 6.2空间的协调—文件系统（文件）

## 一.文件系统的实现

### 1.1系统文件总览

分类：

按来源划分：

- 系统文件——操作系统开发商提供的文件，包括内等关键部分。普通用户对这部分文件没有访问权限，只有在系统更新的时候才会被覆写
- 中间件文件——程序设计语言，驱动程序和中间件开发商提供的文件。普通用户只能读和执行文件，只有在安装新功能时才会被添加，一旦田间则不会被消除
- 用户文件——用户自行创建的文件，包括各种应用程序，数据库和文档等。
- 临时文件——由用于程序或系统生成的缓存性质的文件。这些文件一般体积小，零碎，而且在使用过一次后便无其他作用，需要定期清理。

按性质划分：

- 索引文件——存放关于其他文件学习的文件。目录文件，内容索引文件，软连接都可以看作索引文件的一种。
- 设备文件——实际上不是一个文件，但被抽象成一个文件的设备或系统运行状态信息，部分设备文件还可以用来做跨进程通信（IPC）
- 普通文件——存储用户信息的文件。

按权限划分：

- 不可访问文件——普通用户无权访问的文件
- 只读/写文件——普通用户只能读写的文件
- 可执行文件——含有进程的描述，可以用以启动进程的
- 隐藏文件——一般不展示给用户的文件



### 1.2分区：GPT

GUID（global unique ID）

一个128位的随机产生的ID，几乎可以保证世界上没有两个相同的。可以看成是某种哈希值标 签，也称为Universally Unique ID（UUID）。

磁盘分区：将一个物理硬盘互粉成若干个逻辑区域的过程

GPT（GUID partition Table）

是一种磁盘分区表的标准，用来管理硬盘上的分区，GUID表示全局唯一标识符，Partition Table代表磁盘分区表。

和MBR分区表相比，GPT支持更大的硬盘容量和更多的分区

GPT分区描述符：每个分区都有一个对应的分区描述符，用于描述该分区的信息，每个分区描述符都是一个128字节的数据结构，其中包含分区的其实地址，大小，GUID等信息。

| **字节地址** | **字节长度** | **描述**     | **设置**                                                     |
| ------------ | ------------ | ------------ | ------------------------------------------------------------ |
| 0x00         | 16           | 分区类型GUID | 系统自行决定类型与GUID的对应  ，该字段标识了该分区的类型，例如普通数据分区、EFI系统分区、Microsoft保留分区等。 |
| 0x10         | 16           | 分区GUID     | 随机生成一个  ，该字段标识了该分区的唯一标识符，也是全局唯一的。这个GUID可以用来在不同的系统中唯一地标识该分区， |
| 0x20         | 8            | 分区起始LBA  | 这两个字段标识了该分区在磁盘上的起始位置和大小。通常情况下，每个分区的大小是以扇区为单位进行计算的。 |
| 0x28         | 8            | 分区结束LBA  | -                                                            |
| 0x30         | 8            | 分区属性     | 第0位置位代表系统固件，第1位置位代表操作系统恢复分区等。  该字段标识了该分区的一些属性，例如是否为只读分区、是否为隐藏分区等。 |
| 0x38         | 72           | 分区名       | 该字段标识了该分区的名称，可以用于在文件系统中显示分区的名称。  - |

![image-20230425175239915](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230425175239915.png)





### 1.3磁带：LTFS

线性磁带——数据磁带，容量大，价格便宜，适合备份大量数据使用，

只写，可以作为法律文书，商务合同等防篡改只读文档

发展史：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423162603404.png" alt="image-20230423162603404" style="zoom:50%;" />

磁带介质的特点：

1. 顺序读写：磁带是顺序读写的，不能随机读写
2. 价格便宜：单位容量价格便宜

适合磁带的文件系统：

1. 顺序读写性能好
2. 空间利用率高

节约存储器的方法：

**线性磁带文件系统LTFS**

一种适合于磁带的文件系统。**顺序读写快、空间利用率高**，并自带压缩 功能：文件存储到介质上之前会被自动无损压缩，读取时则**自动解压缩**， 最大限度节省介质容量。

**LTFS分区**

分为标签区和内容区

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423163057016.png" alt="image-20230423163057016" style="zoom:33%;" />

1. 标签区：<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423163153760.png" alt="image-20230423163153760" style="zoom:25%;" />

   保存卷标

2. 内容区：<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423163204086.png" alt="image-20230423163204086" style="zoom:25%;" />

   首先是索引区，该区域是应该XML文件，描述从文件名到文件内容位置的映射

如何修改文件？

无法直接追加

只能把更新后的文件卸载磁带最后面

这样就会存在一个老版本和一个新版本

**代数**——新版本的索引块中会标明一个比老版本更高的代数，用来判断哪个索引是最新的。

老版本的索引中有一个指针指向新版本的索引，

新版本中索引中有一个指针指向老版本的索引，这样就可以相互查找

唯一释放所有空间的方法就是重新初始化文件系统

缺点：浪费 空间

优点：可以做版本迭代



### 1.4硬盘EXT4 

历史：<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423164307282.png" alt="image-20230423164307282" style="zoom:67%;" />

**块组**——EXT4将磁盘上的设备块按照一定的数量组成块组

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423164612897.png" alt="image-20230423164612897" style="zoom:67%;" />

块组也由自己的描述头进行描述

| **字节地址** | **字节长度** | **名称**                   | **描述**                             |
| ------------ | ------------ | -------------------------- | ------------------------------------ |
| 0x00         | 4            | bg_block_bitmap_lo/hi      | 块位图地址                           |
| 0x04         | 4            | bg_inode_bitmap_lo/hi      | inode位图地址                        |
| 0x08         | 4            | bg_inode_table_lo/hi       | inode表地址                          |
| 0x0C         | 4            | bg_free_blocks_count_lo/hi | 块组中空闲块数                       |
| 0x0E         | 4            | bg_free_inodes_count_lo/hi | 块组中空闲inode数                    |
| 0x12         | 2            | bg_flags                   | 块组状态（未初始化、初始化好、全零） |
| 0x1E         | 2            | bg_checksum                | 块组头校验和                         |

超级块——EXT4文件系统的全局描述

![image-20230423165816507](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423165816507.png)

为什么超级快在每个块组都由一份可选拷贝？防止破环的时候全部被破坏

**索引节点inode**

inode内部描述了文件的大部分属性

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423170034264.png" alt="image-20230423170034264" style="zoom:70%;" />

**文件模式i_mode**——文件权限

读，写，执行三个独立权限，

用户分为三类：拥有者，本组用户，其他用户

i_mode可以叠加

![image-20230423171216381](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423171216381.png)

访问控制方法：DAC（自主访问控制）

RBAC（基于角色的访问控制）

**特殊文件的i_mode**——imode前面还有些位，用来标记文件的性质（按性质分类）

![image-20230423172045529](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423172045529.png)

**i_block内部结构**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423172416473.png" alt="image-20230423172416473" style="zoom:67%;" />

EXT4引入了**扩展记录树**的概念，不再使用固定的索引。一个扩展记录的 长度最多可达1000块以上。每颗树都分树头结点、中间结点和叶子结点 三种，叶子结点指向真正的扩展记录地址，中间结点则负责按照二分查 找法或多分查找法解析到叶子结点。每个结点本身的大小都是12字节

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423172642531.png" alt="image-20230423172642531" style="zoom:80%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423173337356.png" alt="image-20230423173337356" style="zoom:80%;" />

**目录文件的内容**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423173415553.png" alt="image-20230423173415553" style="zoom:80%;" />

根据文件名称得到哈希值，在查找哈系数的带具体的目录项

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423173528190.png" alt="image-20230423173528190" style="zoom:80%;" />

根据文件名称得到哈希值，在查找哈希数来找到目录项

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230423173909489.png" alt="image-20230423173909489" style="zoom:80%;" />

**抗损性** EXT4文件系统通过日志来防御意外掉电。

**日志 Journal**

 文件系统在进行操作时，

（1）将操作写入日志，

（2）按照日志条目去操作文件系统，

（3）在完成这些操作后消除掉日志条目。

这样， 一旦掉电发生，就可以通过查询日志来了解哪些操作没有完成。这样， 每一个操作就都是原子化的事务（Transaction）。

**日志文件系统 Journaling File System**

 带有日志恢复功能的文件系统。现代文件系统普遍都是日志文件系统。

**问题** 日志文件系统中，日志与文件系统掉电时的状态关系可能有哪些？

 **情况一** 日志条目写入未完成。

 **情况二** 日志条目写入完成，但操作未执行完毕。

 **情况三** 操作已经执行完毕，但日志条目未被消除。

 情况二与情况三怎么区分？怎么知道操作是否完成？



**情况一** 日志条目写入未完成。

 **解决方案** 下次上电时直接删掉不完整的日志条目，相当于最后的操作从未发生。（装作无事发生；本次操作丢失）

**情况二** 日志条目写入完成，但操作未执行完毕。

 **解决方案** 下次上电时根据日志条目**继续执行操作**，执行完毕后消 除掉日志条目。

**情况三** 操作已经执行完毕，但日志条目未被消除。

 **解决方案** 下次上电时**检查日志条目描述的操作是否完成**，若完成则不再重复操作，若未完成则继续操作直到完成，完成后消除掉日志条目。

 **幂等性（Idempotence）**

 对某对象执行任意多次相同操作得到的**结果不变**。

 日志文件系统的完整日志条目即具备幂等性，反复上电执行同一个日志条目得到的文件系统状态是一样的。

**日志文件** 

EXT4的日志也是以文件格式存储的，称为日志文件。它的inode 编号传统上是8号，一般放置在靠近分区中间位置的某个块组内 的连续存储空间上。

 在一般情况下，EXT4的日志**只存储文件系统管理结构操作**，并不储存实际数据，因此在掉电时只能保证文件系统结构的完整性， 正在操作的文件数据的完整性则无法保证。

 除了将日志文件创建在文件系统所在的同一个逻辑设备上，EXT4 也允许在创建文件系统时为日志文件指定专用的存储设备。

**问题** （1）为何要将日志文件放在连续存储空间上？

顺序追加的

 （2）为何这个连续存储空间要靠近分区的中间位置？

访问的平均距离最短

 （3）为何日志不能连实际数据一起存储？这里有什么考虑？

写日志需要时间，实际数据不重要

 （4）将日志创建在其它存储设备上有什么好处？对这种设备的性能和可靠性有什么要求？



### 1.5闪存YAFFS

**嵌入式系统**：对工号，价格，体积都给长敏感的系统，通常只有一个核心处理器

**NAND闪存的特点**









### 1.6池化

**ZFS**：zettabyte File System

设计用于海量存储的灵活型文件系统。

**128位文件系统**，inode 数量时可以增长的，因此支持的文件数量时无限的

**简便的存储池管理**：不需要逻辑卷管理器，文件系统可以直接池化并管理存储设备，并且管理命令非常易用，可以从存储池中随意添加和移除存储设备，存储池的内容个可用性在整个过程中不改变

**数据可靠性**：内置RAID级别，设备损坏时数据可自修复

![image-20230425172010365](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230425172010365.png)

ZFS内置阵列功能：最多可以允许三个磁盘同时损坏

![image-20230425172336851](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230425172336851.png)

对抗突然掉电：Copy-on-Write

![image-20230425172720029](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230425172720029.png)

独立校验和：对抗连续介质损坏

![image-20230425172754202](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230425172754202.png)



### 1.7启动INITRAMFS

系统启动

INITRAMFS:initial RAM File System



### 1.8系统管理：PROC

PROC文件系统：被组织成文件形式的系统管理和状态信息。

这样，文件的权限系统和访问方式也可以套用系统状态信息上，不需要再专门设计一套接口给它们。



## 二.系统文件接口

### 2.1文件访问接口

![image-20230425174056324](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230425174056324.png)

**文件再内核内存中的描述结构**

![image-20230428185009673](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230428185009673.png)





### 2.2访问控制接口

| **Linux原生接口** | **Windows原生接口** | **功能**       |
| ----------------- | ------------------- | -------------- |
| stat              | GetFileSecurity     | 获取文件权限   |
| chmod/fchmod      | SetFileSecurity     | 设置文件权限   |
| access            | -                   | 测试文件权限   |
| fchown            | SetFileSecurity     | 改变文件所有者 |

**磁盘配额限制** 为了防止某用户使用过多磁盘空间，操作系统还允许限制某用 户的最大磁盘用量。

**磁盘共享限制** 部分操作系统提供将磁盘共享到网络的功能。网络可能会引入 额外的攻击面，因此共享时可以指定用户的访问权限。一个常 见的权限设定是只读，这样用户就只能远程读取磁盘上的文件 而无法修改它们。















# 7交互的协调 设备管理（I/O设备）

## 一.设备的概念与分类

### 1.1设备的分类

软件——运行，组织，管理，维护机电设备和物理机制的程序，系统软件，用户软件

硬件——

回顾部分：输入输出设备：

外部设备——输入输出设备，可以实现人机交互和机间通信等功能。

外设接口——包括三个寄存器，数据寄存器，状态寄存器，命令寄存器

信息交换——四种方式：直接交换，查询（轮询），中断，成组传送

编制方式：独立编址/统一编址



**按用途分类**

1. 人机交互设备——用于人和机器之间交互的设备
2. 协处理设备——用于给计算机追加额外计算能力的设备。
3. 通信设备——用于给计算机追加通信能力的设备，有可以分为联机设备和转接设备两个分类
4. 存储设备——用于给计算机追加存储器（一般为外存）的设备

**按速度分类**

1. 高速设备——数据传输速率高于或接近CPU处理能力的设备
2. 低速设备——数据传输速率低于CPU处理能力的设备

为什么数据传输速率的高低是以CPU处理能力来判别的？

 因为CPU是整个计算机的核心，所有的数据都很可能要通过它。 如果数据来得比CPU处理得快，意味着设备要等待CPU；否则， CPU就要等待设备。这两种方案下，为获得最优综合性能，程序的设计方法是不同的

**按数据传输单位分类**

1. 块设备——以固定大小的巨型数据块为单位进行数据传输和处理设备，一般是外存，其IO需要被缓冲
2. 字符设备——以单个或数个字节为单位进行数据传输和处理的设备，一般是鼠标，键盘，显示器，打印机，IO不需要被缓冲，其读写灵活性类似内存
3. 其他设备——不能简单归入块设备或字符设备的设备。这些设备一般是网卡、 数据采集卡等， 其数据一般以存在时间先后顺序的数据包的形 式出现，其I/O需要非常复杂的缓冲方式。

**按可共享性分类**

1. 共享设备——可以被多个任务同时占用的设备。设备将以很小的等待间隔并 发响应多个请求，或以真正并行的方式响应多个请求。

2. 假脱机设备——多个任务无法真正同时占用该设备，但由于该设备具备请求队列，因此可将多个任务的请求并发提交到该队列，设备将以较长的等待间隔依次响应这些请求。

   **假脱机**——**为了缓和CPU的高速性与I/O设备低速性之间的矛盾**，引入了**脱机输入、脱机输出**技术。该技术是利用**专门的外围控制机**，先将低速I/O设备上的数据传送到高速磁盘上，或者相反。

   比如，打印机

3. 独占设备——一般情况下仅能被一个任务占用的设备。切换这些设备对应的 任务需要用户或应用程序主动干预。

**按数据传输方式分类**

1. 直接传输设备——随时准别好读写，且响应迅速的设备
2. 轮询传输设备
3. 中断传输设备
4. 直接内存访问（DMA）传输设备——数据量大或 IO操作频繁

**按真实存在性分类**

1. 物理设备——实际上存在的、有物理实体的设备。
2. 虚拟设备——仅在概念上存在的设备。它有着和真实设备一样的接口，并会 像真实设备那样对操作做出反应，但找不到一个物理实体和它 一一对应。又叫逻辑设备。

![image-20230428194239307](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230428194239307.png)

### 1.2例子：字符设备

**鼠标**

**性能目标** 鼠标对输入的响应必须迅速，这样使用才有好的体验。

**数据的内容** 鼠标传输的数据至少包括鼠标的相对位移，以及按键的状态。

**数据量的大小** 数据量应该很小，就是一个坐标和几个按键的当前状态。

**数据传输方向** 鼠标一般是单纯的输入设备，因此数据是单向流动到计算机的。

**数据传输方式** 鼠标的数据量很小，且仅在操作时产生数据；另一方面，鼠标 对操作的响应必须迅速，因此使用中断传输较好。



**键盘**

**键的类型** 字符数字型，如A-Z、0-9等，每个按键对应一个字符。      

 扩展功能键，如F1-F12、Page Up等，每个按键产生一个动作。

 组合控制键，如Shift、Ctrl、Alt等 ，改变其它按键的含义。

**扫描码** 键盘上的每个键都有一个单字节扫描码，据扫描码可确定操作 的是哪个键、是按下键还是释放键。扫描码的低7位是扫描码的 数字编码, 与键盘上的键一一对应；最高位表示键的操作状态， 当按下键时为0 ; 当释放键时为1。扫描码是一个计算机系统内部 编码，不是该键对应的ASCII码！

**键盘接口原理** 键盘接口对按下键和释放键均向计算机发出中断申请，如果中 断响应条件满足, CPU转去执行键盘中断服务程序。

**中断工作流程** 

（1）从键盘接口读取操作键的扫描码

 （2）将扫描码转换成字符码；

   大部分键的字符码为ASCII码。  

​    无ASCII码键（如组合键Shift、Ctrl等）的字符码为0。

  还有一些非ASCII码键产生一个指定的动作。

 （3）将键的扫描码、字符码存放在键盘对应的字符设备中。



**实时时钟**

实时时钟的功能：读写时间，设置读闹钟

实时时钟的时间基准——晶体振荡器

**定时器**：带可编程计数上限的计数器。一组D触发器负责计数，另一组触发器则储存一个上限值。一个比较器负责比较这两组值，一 旦计数值达到上限值（**溢出**），就将计数值重置为0。

**定时器中断：**一旦定时器的输入时钟频率已知，那么其溢出的时间间隔（时 间片）也就决定了。我们可以设置定时器在每次溢出时**产生一 个中断报告给操作系统**，操作系统就能够**强制定期启动调度器**。

常见的系统定时器溢出周期在100μs-10ms之间

**实时时钟**：一个电子万年历，可以记录时间和日期，并具备闹钟功能。其往往还有一个单独的后备电池供电，用来在计算机主电源不通电时保持时间走时。

其内部是一系列互相串联的定时器。秒定时器的溢出连接到分 定时器的计数时钟输入端，如此继续下去，直到年定时器为止

**实时时钟中断：**实时时钟可以设置闹钟，一旦闹钟时间点到，便允许向操作系 统发送一个中断。该中断除了做日常事件提醒外还可以触发主板定时开关机。



**上电流程**

系统启动时，**从实时时钟读取当前时间**，然后系统便**自行维护时间的走动**。时间在POSIX操作系统中是用自1970年1月1日0时以来经过的秒数表达的，计算机每秒将这个变量递增一次，然后 再通过内置的软件万年历将其转化为日期和时间。

 系统中的一切行为都以系统时间为基准。

**问题一** 随着系统的运行，系统时间和实时时钟时间产生差异怎么办？

 以实时时钟为准，定期从实时时钟读取时间并覆盖当前系统时 间；也可以测量系统时间与实时时钟的流速差值，并对系统时 间进行校准。

**问题二** 接上问，若实时时钟时间与实际时间也不一致怎么办？

 使用NTP等协议联网校准时间，更新系统时间与实时时钟时间。 现代操作系统在联网时往往会自行执行这一操作。

**问题三** 如果一个程序想延时一段时间t后再触发某个操作，怎么办？

**解决方案一** 允许直接编程系统定时器，修改其计数上限值。

**问题四** 允许程序修改系统定时器导致其可以修改时间片长度，会破坏 线程之间的时间隔离。此外，如果有两个程序同时使用延时， 就没法用一个定时器应付了。

**解决方案二** 允许直接编程实时时钟的闹钟，并在闹铃时产生中断。

**问题** 实时时钟中断的分辨率很低，是秒级别的。此外，即便实时时 钟可以有多个闹钟槽位，但这些槽位的数量终究是有限的（一 般十个以内）。一旦使用定时功能的程序多起来就没法处理了。

**能否找到一种方法，用一个定时器模拟出一批定时器？**

**软定时器**   **用系统定时器作为时基**来模拟一系列的软件定时器。当程序需 要定时时间t时，操作系统内核将记录经过的系统定时器嘀嗒数， 待经过t个嘀嗒时就完成软定时器的定时。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505193155355.png" alt="image-20230505193155355" style="zoom:67%;" />

**问题** 用每次时钟中断都必须检查哪些软定时器超时，这是非常频繁的操作。系统中的程序也可能频繁建立和删除定时器。使用什么数据结构来保证增删改查的性能？

**解决方案** 和CFS调度器的选择一样，可以使用**红黑树**保存软定时器的超时时点。

 由于每次到时间的只可能是距离当前时点最近的那个定时器， 因此只要查询红黑树最左侧的叶子结点即可确定有无软定时器 超时。如果最左侧的叶子结点对应的软定时器都未超时，则不需要查询其它结点。

**问题** 虽然红黑树的增删改查都保证是O(logn)，但n很多时候还是显得 太大，logn时间也很久。如何能让这个时间小一些？

**定时器轮** 将定时器按照其超时时间除以某固定值N的余数分成多组。每次检查定时器超时时，只要检查可能超时的那一组就可以了。

 定时器轮还可以分成多层，层数越多、轮子越大，检查的时间 越短。因此，软定时器的超时处理可以非常迅速。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505193552891.png" alt="image-20230505193552891" style="zoom:67%;" />

**问题** 软定时器的最高精度是多少？要怎么提高它？

用系统定时器作为时基，

**软定时器的工作模式**

 软定时器有一次性（One-shot）和周期性（Periodic）两种工作模式。一 次性定时器到期后，系统会删除该定时器；周期性定时器到期后，系统 将依据其周期重新计算下次超时时间，并将定时器重新插入数据结构。



**高精度定时器（HRTIMER）**

 常规定时器是以系统定时器作为时基的，因此其最高精度就是一个时间片。在Linux中，常规定时器又称为低精度定时器，与jiffies变量相关，而 jiffies记录的则是内核启动后经过的时间片数量。

 对网络通信、视频播放、数据采集等场合，这种精度是不够用的，因此 引入了高精度定时器HRTIMER。HRTIMER也是软定时器，但**它的底层硬件是具备高精度一次性倒计时能力**。每次内核处理完一个HRTIMER后，都会**将定时器硬件重编程为下一个软定时器的到期时间**，从而完成不依赖周期性中断的计时。

 **HRTIMER机制一旦启动，低精度定时器机制就不再使用。**但内核中的 jiffies变量因为在很多地方用到，仍然需要维持。对此，内核的做法是， 声明一个周期性的HRTIMER，其到期时间正好是一个时间片，模拟原有的低精度定时器中断。



### 1.3例子：块设备

**机械硬盘**

![image-20230505194809052](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505194809052.png)

![image-20230530231237263](C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230530231237263.png)



**硬盘的接口** 机械硬盘等外存的接口是文件系统，提供按文件名存取文件内容的功能。对于机械硬盘而言，这将会转化成为对具体的CHS地址的寻址，以最终定位到某个扇区

**物理规格** 硬盘制造时的物理规格，包括盘片的数量、盘片的磁道与扇区 划分、磁头的数量、盘片的旋转速度等。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505194957081.png" alt="image-20230505194957081" style="zoom:67%;" />

**几何规格** CHS表示法规定，每个盘片（Platter）上的每一圈都有相同数量 的磁道。在硬盘密度较小时，这不是一个问题，但在现代硬盘 中就会造成外圈磁介质的浪费。因此，现代硬盘的CHS表示法没有物理意义，仅仅是虚拟的编址；改用LBA表示法更合适。

**低级格式化**（低格） 将每个好扇区赋予LBA地址，并写入前导码和ECC纠错码等。还 需要屏蔽坏扇区。完成后，磁盘从物理介质变成一个可用设备。

**盘片斜进量** 磁头本身只能做径向移动，要读取某个扇区只能等待它转过来。为了让读取完 一个磁道后读取另一个磁道的速度加快，每个磁道的1号扇区的起始角度是错开的。这样，上一圈转完读取完磁道，磁头稍作移动就正好等到下一个磁道的开始位置。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505200109192.png" alt="image-20230505200109192" style="zoom:33%;" />

**传统（Conventional）磁记录 vs 叠瓦（Shingled）磁记录**

 为保证读写可靠，传统磁盘的设计中写头总是比读头宽。这会导致盘片面积浪费，降低存储容量。为解决此问题，可将多个磁道叠加起来。使磁道之间的排列更紧密。

 但这样并非没有代价：写一个磁道会覆盖下面的磁道。因此，每次写磁道都需要把会被覆盖的磁道读出来，然后再一并写回去。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505200343139.png" alt="image-20230505200343139" style="zoom:33%;" />

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505200311617.png" alt="image-20230505200311617" style="zoom:33%;" />

**读写单位** 虽然磁盘的设备块是扇区，但操作系统并不会按照扇区来读写 硬盘，因为这个单位太小了，效率不高。操作系统实际使用的 读写单位是**簇（Cluster）**，它是一系列连续扇区的集合。

**磁盘的共享** 磁盘是一个共享设备，这意味着很多进程都会同时提交大量的写盘请求。磁盘的工作效率显著地比CPU低，那么如何处理这些 请求使I/O效率最高？

**提示** 磁道与磁道之间；簇与簇之间；簇内部

**磁道**  越靠近的磁道之间的访问延迟更低（磁头摆动幅度小；ms量 级），同时从内圈往外圈读访问延迟比从外圈往内圈读低（盘片斜进量，μs级）。

**簇** 同一个磁道，从前往后读快，从后往前读慢（扇区的排列顺序； μs级）。一个簇内部的写则最好一次写完。

**主要方面** 在调度磁盘I/O时，主要考虑磁头在磁道上的摆动耗时，因为这 个时间是以ms计算的，远远超过其它耗时。

**排序策略：先来先服务（FCFS）**

 直接按请求的发起顺序来发起磁盘访问。

**优点** 简单。无需做任何顺序调整，直接提交请求即可。

**缺点** 磁盘的寻道时间可能过长。

**排序策略：线性扫描**

 从磁盘头扫描到磁盘尾，在一次扫描中响应所有的请求。

**优点** 理论上生成的就是最优扫描顺序，磁头只在每个磁道处停留一次。

**缺点** 这是一个离线算法。已知所有请求时，才能将它们排序，然后一次性从 前向后满足它们。磁盘请求是应用程序运行过程中动态产生的，因此其次序不好预测（前面讲过类似的情况）。

**排序策略：最短寻道时间优先（Shortest Seek Time First，SSTF）**

 在访问时先计算下次磁头移动的距离，选择最近的磁道进行访问。

**优点** 一定程度上减小了寻道时间。

**缺点** 有可能造成饥饿现象。什么情况会饥饿？怎么改进？

**排序策略：电梯扫描算法（SCAN）**

 将队列中的请求排序，从头扫描到尾，然后再从头开始。在扫描到底之前，不做回溯，直到扫描完成后才一次性拉回来，像电梯一样。

**优点** 一定程度上减小了寻道时间，但不产生饥饿（为什么？）。



**缓冲区buffer** 缓冲区是一个临时的存储区，用以缓和通信双方I/O速度和数据传输单位上的差异，其基本特点是（可含有一定次序重排的） 先进先出队列。

 磁盘返回的读数据都被提交到读数据缓冲区，等待操作系统拿走这些数据；提交到磁盘的读写请求都要在操作缓冲区中进行排队，等到合适的时候再操作磁盘。

 在操作缓冲区中，同一个簇的读写请求会被合并，同一磁道的不同簇之间的读写请求会被按照簇的次序来排序。不同磁道之间的请求则按照某种策略排序。

**缓存cache** 缓冲区的改进，增加了数据存留的功能，不再具备先进先出的特点。现代操作系统的磁盘缓冲实际上都是缓存，它们就像CPU 的缓存那样工作，含有一系列簇的副本；如果操作请求命中它们，就可以免去真正的磁盘读写。这种用来替代缓冲区的缓存习惯上叫做缓冲缓存（Buffer-Cache）。

**缓冲区的类型**

 **单缓冲** 含有一个请求的缓冲区。

 **双缓冲**  含有两个请求的缓冲区。并发能力更好。

 **环形多缓冲** 队列中的多个请求组成一个环形，并有头尾两个指针。头指针负责写，尾指针负责读，如果头赶上尾则说明队列已满，如果尾赶上头则说 明队列已空。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505202512809.png" alt="image-20230505202512809" style="zoom:33%;" />

**缓冲池**

多个缓冲区的集合，由内核各模块共享。程序需要的时候需要申请，用完释放回去，提供统一的接口并且集中管理。

**缓存的写策略**

**写透（Write-Through，WT）**

 对缓存发起的写会立刻被反映到存储器上。

 **写回（Write-Back，WB）**

  对缓存发起的写不会反映到存储器上，而是等待对应的缓存块  被淘汰后才将该块内容写回磁盘。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505203056049.png" alt="image-20230505203056049" style="zoom:67%;" />



### 1.4例子：其他设备

**网卡**

**问题** 操作系统中，网卡（Network Interface Card，NIC）的接口应该是什么样？

 从以下几个角度思考：

 （1）期望达到的性能目的——网卡用来上网，它有两方面要求：一方面需要带宽大，另一方 面又需要延迟低。

 （2）数据的内容——网卡传输的是一系列网络数据包。数据包有一个最大大小 （Message Transfer Unit，MTU），约在1500字节左右（现代网 卡可允许更大的数据包），但却没有最小大小。

 （3）数据量的大小——巨大的数据量。甚至比硬盘的数据量都还来得远要大，很多时 候是网卡在等待CPU，而非CPU在等待网卡

 （4）数据传输的方向——双向传输，具备一个发送队列和一个接收队列。

 （5）数据传输的方式——中断传输或DMA，DMA是主要数据搬运方式，中断仅做通知。

**DMA工作流程**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230505204224812.png" alt="image-20230505204224812" style="zoom:50%;" />

**中断分发**——在多喝处理器中，中断控制器库将设备的中断平均分配给每个CPU，这样就有足够的CPU来处理应付高中断的设备

**中断节流**——限制设备产生的中断率，也即在一定时间内产生的中断上限数目。对于网卡而言，我们可以将每个包产生一个中断改为每一组包产生一次中断，这样就降低中断对CPU的占用率，也叫中断裁决。

**带超时时间的中断节流**——报的数量达到一定值，或者第一个包到来后经过延迟时间，即产生一个中断。这样，在包多的时候可以发挥中断节流的优势，有不至于在包少的时候增加过多的延时。

**网络协议栈**——专门用来处理网卡数据流的协议栈，在网络中，每个包的延迟和可靠传输都是不确定的，因此在数据链路层和网络层之外还需要额外的传输层协议，他们要负责报的重排序，以及丢包重传，最终将一系列零散的数据包组成可以用的数据流送给各个应用程序。

**带多收发队列的中断分发**——每个CPU使用独立的收发队列，并且网卡通过IP封包的四元组（源、源端口、目的、目的端口）将其分发到不同的队列。这样一来解决了队列争用问题，使无锁成为可能；二来不同传输 层链接的包会去不同的队列中，方便CPU就地处理。此功能还可以结合NUMA，将属于某CPU的队列放在该CPU直接连接的内存中，最大限度地降低处理延迟。



## 二.设备与驱动程序

### 2.1驱动程序的概念

定义：直接控制设备的接口程序。

通过直接读写控制器中的寄存器来操作设备

一般运行在内核态，是内核的一部分

驱动程序是设备依赖的

驱动程序的目标是将设备的特性抽象掉，保留设备的共性，以保持内核的其他部分以及用用程序的设备独立的。

**驱动程序的功能**：
查找设备

初始化设备

响应设备请求

响应软件请求



Linux70%都是驱动

设备操作的全景

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230516162224030.png" alt="image-20230516162224030" style="zoom:50%;" />

阻塞：如果设备一时间无法立刻完成操作，就要阻塞发起操作的应用程序线程，直到设备完成操作，发起中断 ，才能解除该阻塞。

**中断响应全景**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230516162447968.png" alt="image-20230516162447968" style="zoom:50%;" />

上半部分：运行在中断上下文

下半部分：一个独立的内核线程

好处：如果对时延敏感，或不能被打断，放在上半部；其它都放在下半部。

**驱动程序的基本组成**

1. 初始化例程：初始化驱动程序自身
2. 设备识别例程：负责查找，匹配和初始化设备
3. 请求分发例程：将内核IO子系统的请求变化后发送个设备
4. 中断服务例程：响应中断请求
5. 下半部例程：处理中断（但是并非很要紧）

**Linux驱动程序：*.ko内核模块**

*.ko内核模块：可以在内核运行时被加载或卸除，使宏内核获得微内核那样的灵活性

内核模块运行在内核空间，内核模块之间可以互相访问，任一内核模块故障都会导致死机

编译：Linux的驱动都作为内核模块存在，M成为独立内核模块，Y编入内核

加载：insmod rmmod动态装载和卸除内核模块（sudo权限）

查询：lsmod

**windows驱动程序：*.sys驱动文件**



### 2.2驱动程序栈：USB

Unibversal Serial Bus通用串行总线

解决外设连接难，接口标准多的问题

硬件框架：USB设备——（USB桥片）——>PCle总线——（南桥）——>CPU

热插拔

端口供电

便携接口

数据传输：基于数据包，主机端发起的（只有主机发起问询，设备端才能恢复数据，设备无法主动发起数据给主机）

四种传输方式：

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230516171439514.png" alt="image-20230516171439514" style="zoom:50%;" />

**“中断传输”** 中断传输在USB协议层面并不是基于中断的，而是基于轮询实现。 当设备选择了中断传输时，主机会保证留出总线带宽，严格按 照指定的周期（如1ms）去轮询设备

**描述符**：

1. 设备描述符，主机会定期扫描 USB端口，一旦它发现有设备被插入（信号线电平变化），就发出控制 传输请求，要求读取设备的设备描述符。

2. 配置描述符：接下来，主机将请求配置描述符，查看设备 的可用工作配置，包括供电要求、功能选项等等。当每个配置描述符被读取时，设备会将该描述符的下属接口描述符和端 点描述符一并发回。USB主机将根据驱动程序和用户程序的输入，选择 一种配置，此后USB设备便工作在此配置下。

3. 接口描述符：描述一个配置中的一部分子功能。比如，一个带显示的手持终端就可以 有两个接口，一个接口负责显示，另一个接口负责按键控制。 

4. 端点描述符：描述子功能中包含的一个通信信道（pipe）。比如，键盘可以有两个信 道，一个信道负责向上传送按键通断码，另一个信道则负责下发按键背 光颜色与强度。每个端点都是单方向的：要么是上行端点（IN，设备到主机），要么是 下行端点（OUT，主机到设备）。端点0是一个例外，它固定用来做控制 端点，且每个USB设备都有它；它可以进行双向传输

编写USB设备驱动，就是对设备进行配置，并且对端点进行数据传输。 USB子系统的编写者（或少数几个控制器厂商）已将USB控制器的驱动 写好，因此编写“设备驱动”仅需要调用内核级库函数，非常方便。

**USB 驱动程序栈层级**

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230516174039885.png" alt="image-20230516174039885" style="zoom:50%;" />

如果要编写USB设备驱动，调动USB控制器驱动就行，不需要学习硬件知识，

完成USB设备 和USB控制器的解耦，成就USB的兼容性

**USB设备类通用驱动程序**

考虑到很多USB设备的功能都是雷同的，USB-IF准备了很多标准设备类（和子类），这些设备类的配置、接口、端点描述都是模板化的。只要在设备类描述符（XXX Class Descriptor）中提供必要信息，系统就会直接加载通用驱动。这就是所谓的**USB免驱动**；如果厂商生产的设备完全遵照（或部分接口遵照）一个设 备类的描述，那么在用户看来就等于“不需要任何驱动程序”。

考虑到这些驱动程序不属于任何一个厂商，操作系统开发商往 往会内置它们。这就是为何键盘鼠标总是不需要额外安装驱动

## 三.应用程序与设备

### 3.1接口的分类

按照接口对应的**设备**来分类

1. 人机交互设备接口
2. 显示设备接口——OpenGL，DirectX等图形学库，或者虚幻，Unity等三维引擎。提供大量的函数库来帮忙绘制界面
3. 网络设备接口——套接字
4. 存储设备接口——文件系统提供的文件操作

按照接口的**阻塞性**分类

1. 阻塞接口——当设备无法完成的时候，在接口上请求的线程将阻塞，直到设备返回数据
2. 非阻塞接口——当设备无法即时完成I/O操作或返回消息时，该接口将立即返回并将当前设备状态报告给调用线程。线程可以以合适的间隔轮询此接口，直到获取到数据。不一定需要操作系统介入。

**问题一** 

（1）为什么需要非阻塞接口？一切接口都阻塞不好吗？

（2）阻塞接口和非阻塞接口哪个效率高？

（3）设备出故障，无法完成操作，导致线程永久阻塞怎么办？

**答案** （1）试探是否有数据，或者轮番试探多个设备；（2）数据量 小的设备阻塞效率高；数据量大则反之。（3）增加超时返回。

**问题二** 如何不使用轮询非阻塞接口的方法，同时等待多个接口？

按照接口**同步性**分类

1. 同步接口——用同一个接口操作来发起I/O请求和接收I/O结果；当接口返回时， I/O结果必定已知，要么完成，要么失败。

2. 异步接口——用一个接口操作来发起I/O请求，并用回调函数来接收I/O结果； 发起请求的I/O接口操作返回时，请求可能还在处理中，I/O结果要等到回调函数被调用时才知道。

   回调函数callback：被操作系统挥着运行时环江调用而非被应用程序性主动调用的用户空间函数，类似中断向量，回调函数越短越好。

   要使用回调函数，需要

    （1）定义该回调函数，

    （2）将回调函数的函数指针和触发它的条件注册给系统，

    （3）系统将在满足条件时调用它，提醒应用程序某事件发生

### 3.2设备的共享

**设备同时联机操作 Simultaneous Peripheral Operations On-Line，Spool**

 如果该设备同时只能执行一个程序的操作，但程序不关心也不 等待操作的执行完成才能继续进展，则各程序可以将请求提交 到队列，设备则从队列中依次拿出请求执行。相当于将异步I/O 操作转化成了一个同步I/O操作。这种设备就是之前介绍的假脱 机设备，这种操作也叫做假脱机操作。最常见的是打印机。

**守护进程**

 在实际实现中，对于每个假脱机设备，我们都会启动专用进程

用来管理队列和操作I/O，而其他进程则把这个进程当成虚拟设 备并操作它。这个专用进程随着设备的启动而启动，随着设备 的关闭而关闭，因此叫做守护进程。

问题：如果程序需要独占设备，关心设备的操作何时完成，并需要等待它？

解决：加锁









# 8互斥和同步

## 一.指令流间的竞争

参与关系的基本单位——指令流

指令流之间的关系：

竞争关系——最常用的是文件和设备的争用，争用所有权

合作关系——操作的执行按一定的先后次序完成

互补相干——但是所有指令流都有占用量限额的竞争关系

用数学语言描述指令流之间的关系——偏序集（自反，反对称，传递）

严格的偏序集的关系图就是一个==有向无环图==

### 1.1 临界区

**临界资源**——不能被两个指令流同时使用的资源。只能分别在两个指令流中独占共享。

**共享资源**——将一次允许多个进程同时使用 的资源称为 共享资源。

**临界区**——访问临界资源的程序段，临界区不能并行的，越短越好

临界区的进入和退出

进入临界区（判断+等待）——>访问临界区（访问临界资源）——>退出临界区

**互斥**——临界资源不能斌回复使用的现象

### 1.2 自旋锁

**单标志法**

  **算法基本思想**：设置一个 公用变量 turn，用于指示被允许 进入临界区的进程编号，即若 turn = 0，则允许 P0 进程进入临界区。算法可保证同一时刻只允许一个进程进入临界区，但两个进程必须交替进入临界区。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230530173507943.png" alt="image-20230530173507943" style="zoom:67%;" />

解决了临界区互斥问题，达到了绝对公平，但是两个指令流对临界区的访问频率不同的话，就会导致饥饿。

**双标志先检查法**
  **算法基本思想**：设置 一个布尔型数组 want[]，数组中各个元素用来标记各进程想 进入临界区的意愿，比如 want[0] = ture 意味着 0 号指令流s0 现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有其他进程想进入临界区，如果没有，则把自身对应的标志 want[i] 设为 true，之后开始访问临界区。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230530173825711.png" alt="image-20230530173825711" style="zoom:67%;" />

**双标志后检查法**

  **算法基本思想**：双标志先检查法的改版，与前一个算法不同，采用 先上锁后检查，来避免上述问题。

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230530173734402.png" alt="image-20230530173734402" style="zoom:67%;" />

解决了临界区互斥的问题，但是两个指令流会循环等待对方，会死锁

解决死锁问题：指令流会短暂放弃进入临界区的愿望，给对方一个机会

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230530174034539.png" alt="image-20230530174034539" style="zoom:67%;" />



### Peterson 算法

  **算法基本思想**：结合双标志法、单标志法的思想。如果双方都争着想进入临界区，那可以让进程尝试 孔融让梨(谦让)，做一个有礼貌的进程。进程在进入区要做的步骤： ① 主动争取 ② 主动谦让 ③ 检查对方是否也想使用，且最后一次是不是自己说了客气话

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230530174400135.png" alt="image-20230530174400135" style="zoom:67%;" />

解决了临界区互斥问题，不会出现死锁，活锁，饥饿问题



为了实现对临界资源的互斥访问，同时保证系统整体性能，需要遵循以下原则：
 ① 空闲让进：临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区；
 ② 忙则等待：当已有进程进入临界区时，其他试图进入临界区的进程必须等待；
 ③ 有限等待：对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）；
 ④ 让权等待：当进程不能进入临界区时，应立即释放处理机，防止进程忙等待。

**互斥锁**——一种用以控制临界区访问的互斥访问原语，分为加锁和解锁两个原子操作，进入临界区加锁，退出临界区解锁

加锁——检查条件，在满足的时候获得加锁的权力，这个过程中，指令流只要在循环判断检测条件，做忙等待，像旋转的陀螺，称为自旋锁。

解锁——释放锁的拥有权。

**多指令流的自旋锁**

Peterson算法推广到多指令流。——>竞标赛锁

<img src="C:\Users\lenovo\AppData\Roaming\Typora\typora-user-images\image-20230530175746236.png" alt="image-20230530175746236" style="zoom:50%;" />

**多指令流自旋锁：过滤器(Filter)算法**

它是Peterson锁算法在多线程上的直接一般化。 

**多指令流自旋锁：烘焙坊（Bakery）算法**



**关中断（或锁调度器）实现自旋锁：CLI/STI**

**原子指令实现自旋锁：SWAP/XCHG**

**原子指令实现自旋锁：TAS/BTS**

**原子指令实现自旋锁：CAPXCHG/CAS**



 ### 1.3 阻塞锁

### 1.4 管程



## 二.指令流间的合作

### 2.1条件变量

我们需要一种同步措施：能够

- 让指令流阻塞在临界区，
- 能够在阻塞时即时释放锁
- 能够在满足某些条件时解除阻塞并得到锁

**条件变量**

一种同步原语，可以使指令流阻塞并等待，直到某个条件发生。它总是 与一个锁配合使用：如果条件不满足，则指令流自动释放锁并加入等待 队列；而当条件满足时，等待队列头部的指令流将被唤醒并自动恢复对 锁的持有。

**条件变量的基本操作**

1. 阻塞，等待（Wait）：一个线程在条件变量上等待，直到某个条件满足为止。等待操作会自动释放相应的互斥锁，使其他线程能够访问共享资源。线程在等待时处于阻塞状态，直到被唤醒。
2. 唤醒，唤醒（Signal/Notify）：当某个线程改变了条件变量所表示的条件，使得其他线程可能满足等待条件时，它可以通过唤醒操作通知等待的线程。被唤醒的线程将从等待状态转换为就绪状态，然后等待获取互斥锁来访问共享资源。
3. 唤醒全部

**惊群效应**

惊群效应（英文：Thundering Herd）是指在并发编程中的一种现象，当多个进程或线程等待同一个事件或资源时，一旦该事件或资源可用，所有等待的进程或线程会同时被唤醒，但只有其中一个能够获得资源或执行任务，其他进程或线程则需要重新等待。这种情况会导致系统资源浪费和性能下降。

为了避免惊群效应，可以采取以下策略：

1. 互斥锁（Mutex）：在条件变量之前使用互斥锁来确保只有一个线程能够获得资源或执行任务。当条件变量满足时，只有获得互斥锁的线程可以进入临界区，其他线程则需要等待互斥锁。
2. 唤醒一个线程：只唤醒一个等待的线程，而不是全部唤醒。通过选择合适的等待队列管理策略，只唤醒一个线程来处理满足条件的情况，其他线程继续等待。

**条件变量的两个语义**

1. Hoare语义：
   - 在Hoare语义中，等待线程在收到信号并被唤醒后，必须重新获取与条件变量相关联的互斥锁才能继续执行。
   - 当等待线程被唤醒后，它会尝试获取互斥锁，只有成功获取互斥锁的线程才能继续执行。如果线程无法获取互斥锁，它将继续等待，直到能够获取到为止。

2. Mesa语义：

- 在Mesa语义中，等待线程在收到信号并被唤醒后，不需要重新获取互斥锁就可以继续执行。
- 当等待线程被唤醒后，它会尝试继续执行，而不必等待互斥锁的所有权。如果线程发现条件不再满足，它将重新等待条件。

### 2.2信号量

信号量（Semaphore）是一种并发编程中用于线程同步和互斥的机制。它是一个计数器对象，用于控制对共享资源的访问。

信号量主要有两个操作：

1. P（wait）Acauire操作：当线程需要访问共享资源时，它必须先执行P操作。如果信号量的计数器大于0，则线程可以继续执行并将计数器减1；如果计数器为0，则线程将被阻塞，直到有其他线程释放资源。
2. V（signal）Release操作：当线程使用完共享资源时，它必须执行V操作来释放资源。V操作会将信号量的计数器加1，并且如果有线程在等待该信号量，则唤醒其中一个等待线程。

信号量的作用是通过控制对共享资源的访问来实现线程间的同步和互斥。它可以用来解决生产者-消费者问题、读者-写者问题和多线程资源争用等并发编程中的典型场景。

在使用信号量时，需要合理地设置初始值和选择适当的操作顺序，以确保正确的同步和互斥行为。过多或过少地使用信号量可能导致死锁、饥饿或资源浪费等问题。

需要注意的是，信号量并不保证公平性，即它不能保证等待时间最长的线程先获得资源。如果需要公平性，可以使用更高级的同步机制，如条件变量和互斥锁的组合。



**对比互斥锁，条件变量，信号量**

| **项目** | **互斥锁**                           | **条件变量**                       | **信号量**                                 |
| -------- | ------------------------------------ | ---------------------------------- | ------------------------------------------ |
| 主要作用 | 临界区互斥                           | 基于任意条件的同步                 | 基于资源数量的同步                         |
| 使用方法 | 同一个指令流内成对的lock()和unlock() | 与锁配对使用，  但对使用场景无要求 | 生产者负责release()，  消费者负责acquire() |
| 复杂程度 | 低                                   | 中等                               | 高                                         |
| 唤醒丢失 | -                                    | 可能丢失                           | 基于计数，不会丢失                         |
| 可替代性 | ？                                   | ？                                 | ？                                         |

问：信号量能否代替互斥锁

答：能，只要将信号量的数量初始化为1，然后用PV在临界区前后调用即可

问：信号量能否代替条件变量

答：大多情况下可能代替，而且信号量带计数，不会丢失唤醒，很多时候无需额外加锁

问：什么场景信号量不能代替条件变量

答：使用到全部唤醒（cond_signal_all）的场合，或者非标准生产者- 消费者场景的场合。



**吸烟者问题**

吸烟者问题（Smokers Problem）是经典的并发编程问题，描述了三个吸烟者和一个供应者之间的协作。

问题描述如下： 有三个吸烟者，分别需要烟草、纸和火柴三种资源才能吸烟。还有一个供应者，他持续地提供两种资源给吸烟者。每个吸烟者只有在拥有自己所需的两种资源时才能吸烟。

具体的要求如下：

1. 烟草吸烟者拥有纸和火柴资源。
2. 纸吸烟者拥有烟草和火柴资源。
3. 火柴吸烟者拥有烟草和纸资源。
4. 供应者循环提供两种资源中的一种，供应者选择的资源不能与任何一个吸烟者所需的资源相同。

问题的目标是设计一个同步机制，使得吸烟者能够按照自己所需的资源来顺利地吸烟，而供应者在供应资源时能够正确地满足吸烟者的需求。

解决吸烟者问题的一种常见方法是使用信号量和互斥锁的组合。可以使用三个信号量来表示烟草、纸和火柴的可用性，一个信号量用于控制供应者的行为。此外，还可以使用互斥锁来确保每个吸烟者独占所需的两种资源。

以下是一种可能的解决方案：

1. 创建三个信号量：tobacco（烟草）、paper（纸）和match（火柴）。
2. 创建一个互斥锁供应者Mutex。
3. 供应者循环执行以下操作：
   - 获取供应者Mutex。
   - 随机选择两种资源之一。
   - 释放对应的信号量（例如，如果选择了烟草和纸，则释放tobacco和paper信号量）。
   - 释放供应者Mutex。
4. 每个吸烟者循环执行以下操作：
   - 获取自己所需的两种资源的信号量（例如，烟草吸烟者获取paper和match信号量）。
   - 吸烟。
   - 释放所需资源的信号量。

这种解决方案通过信号量和互斥锁的合理运用，确保了吸烟者只有在拥有所需的两种资源时才能吸烟，供应者也能正确地提供所需的资源。



**无等待数据结构**



## 三.死锁和活锁

### 3.1 预防和避免

### 3.2 检测和恢复
